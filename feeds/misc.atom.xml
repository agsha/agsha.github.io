<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>A Pelican Blog - misc</title><link href="/" rel="alternate"></link><link href="/feeds/misc.atom.xml" rel="self"></link><id>/</id><updated>2024-10-11T22:44:00+00:00</updated><entry><title>Notes on the rank theorem in linear algebra</title><link href="/notes-on-the-rank-theorem-in-linear-algebra.html" rel="alternate"></link><published>2024-10-11T22:44:00+00:00</published><updated>2024-10-11T22:44:00+00:00</updated><author><name>Sharath Gururaj</name></author><id>tag:None,2024-10-11:/notes-on-the-rank-theorem-in-linear-algebra.html</id><summary type="html">&lt;p&gt;I have always been fascinated by the rank theorem in linear algebra. It is known sometimes by other names:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The rank-nullity theorem&lt;/li&gt;
&lt;li&gt;Fundamental theorem of linear algebra (part 1)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Stated simply, The rank theorem asserts that in any matrix, the row rank is equal to the column rank.&lt;/p&gt;
&lt;p&gt;The result …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I have always been fascinated by the rank theorem in linear algebra. It is known sometimes by other names:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The rank-nullity theorem&lt;/li&gt;
&lt;li&gt;Fundamental theorem of linear algebra (part 1)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Stated simply, The rank theorem asserts that in any matrix, the row rank is equal to the column rank.&lt;/p&gt;
&lt;p&gt;The result of the theorem always seems a bit magical to me (as I will explain later). It is as if someone told me the following - In a room, close your eyes and randomly throw a crumpled ball of paper. It will always land in the waste paper bin!&lt;/p&gt;
&lt;p&gt;So naturally, I have put quite a bit of effort to understand the proof, but most proofs seem like "rabbit-out-of-a-hat". And yet, it is a fundamental theorem that is used ubiquitously in linear algebra.&lt;/p&gt;
&lt;p&gt;In this post, I hope to give an intuitive understanding of the rank theorem. The structure of this post is as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Cover some basic definitions and theorems to get everyone on the same page&lt;/li&gt;
&lt;li&gt;Show just how profound and non-obvious is the result of the theorem&lt;/li&gt;
&lt;li&gt;Illustrate an intuitive way of thinking about the theorem&lt;/li&gt;
&lt;li&gt;Explore some other common proofs of the theorem&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The target audience for this post is people who already have a decent understanding of the matrix-oriented proofs, as well as the more abstract proofs, and who are looking for a more intuitive explanation of the result.&lt;/p&gt;
&lt;p&gt;Although I try to cover most of the basic facts for the sake of completeness and as a refresher, It is by no means sufficient as an introduction to someone who is not aware of the subject.&lt;/p&gt;
&lt;p&gt;In particular, familiarity with the following two books will be immensely helpful&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://www.amazon.com/Introduction-Linear-Algebra-Gilbert-Strang/dp/1733146679/ref=sr_1_1?crid=1JW0E99JN5SKE&amp;amp;dib=eyJ2IjoiMSJ9.F5NXQBUERLV6mEXR0WvWdC1VIo5KtbzV8WZcVUP2Dg4cb4i4DR40XDLNrVXwixRol38MYo6BTvYpyNTQVQ0gImwXuiqCQ59piMxv2_tRyE44IAugYBc4-ZNbbapORHJvxiCa1y1Dmv2TKy9e3Ss9FNH_k5b179BLKOjRGpHcSZiTDj5njPwn8N8jmqDIILP_SJ-OGLVSjZwqkUiOw5K5xa7fM9dhW9Yd2ITMbkE1hR4.ea-vft9gJC1k1gLg1yAzgwQ31yIYCgzAnEuQE1JHUwo&amp;amp;dib_tag=se&amp;amp;keywords=introduction+to+linear+algebra+gilbert+strang&amp;amp;qid=1728671128&amp;amp;s=books&amp;amp;sprefix=introduction+to+linear+algebra+gilbert+strang%2Cstripbooks%2C277&amp;amp;sr=1-1"&gt;Linear algebra and its applications - by Gilbert Strang&lt;/a&gt;. This book is more of an application oriented introductory textbook for undergrads&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.amazon.com/Linear-Algebra-Its-Applications-Peter/dp/0471751561/ref=sr_1_1?crid=3DTKAMQYELAH8&amp;amp;dib=eyJ2IjoiMSJ9.QS-53qTNH2oNYlinearly independentfPP8d2aRRsbCOzpvSrfGrUdb_pa0qIz1_f0pjjxnk1y_WceOgvpwmS6HwJSYPaL6XGVINCFDPGVG98qD5yNvmlUTYpNvoNGbu17lBruy_brAbN0oG9iDTdBS8LO0LoaWQMFoTOg.r4QjPYISMr7QqB_7PAKk3omHi-hcFnfYlbUBYVR2UOA&amp;amp;dib_tag=se&amp;amp;keywords=linear+algebra+-+by+Peter+Lax&amp;amp;qid=1728671251&amp;amp;s=books&amp;amp;sprefix=linear+algebra+-+by+peter+lax%2Cstripbooks%2C260&amp;amp;sr=1-1"&gt;Linear algebra and its applications - by Peter Lax&lt;/a&gt;. This book is also an undergrad texbook, Contrary to its name, it is a very abstract book, with a more rigorous approach, suitable for (example), an "honors" undergraduate course&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Alright, lets begin!&lt;/p&gt;
&lt;p&gt;Let's start with some basic definitions and simple theorems, whose proof I shall skip. The proofs should be part of any standard linear algebra fare (in particular, the textbook by Peter lax)&lt;/p&gt;
&lt;h1&gt;Basic definitions and theorems&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;vector space&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A vector space over a field of scalars is a mathematical object that supports&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;addition&lt;/li&gt;
&lt;li&gt;multiplication by a scalar&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;linear combination&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A linear combination of vectors &lt;span class="math"&gt;\(x_1, x_2, \cdots, x_n\)&lt;/span&gt; is a vector of the form &lt;span class="math"&gt;\(k_1x_1+k_2x_2+\cdots+k_nx_n\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;subspace&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A subspace &lt;span class="math"&gt;\(Y\)&lt;/span&gt; of a vector space &lt;span class="math"&gt;\(X\)&lt;/span&gt; is a subset that is closed under the vector operations. i.e., linear combination of members of the space is also a member of the space. Please note here the difference between a &lt;em&gt;subset&lt;/em&gt; and a &lt;em&gt;subspace&lt;/em&gt;. A subset need not be closed under the vector operations&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;linear independence&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A set of vectors &lt;span class="math"&gt;\(x_1, \cdots, x_n\)&lt;/span&gt; are linearly dependent iff&lt;/p&gt;
&lt;div class="math"&gt;$$
k_1x_1 + k_2x_2 + \cdots + k_nx_n = 0
$$&lt;/div&gt;
&lt;p&gt;where the &lt;span class="math"&gt;\(k\)&lt;/span&gt;s are scalars and not all of them are zero. If the vectors are not linearly dependent, they are called linearly independent. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;basis vectors&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A finite set of vectors that span a space &lt;span class="math"&gt;\(X\)&lt;/span&gt; and are linearly independent, are called the basis. The number of vectors in the set is called the &lt;strong&gt;dimension&lt;/strong&gt; of the space (denoted as &lt;span class="math"&gt;\(dim\ X\)&lt;/span&gt;). There can be many different sets of basis vectors but the dimension is always the same&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Completion of a partial basis&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Every linearly independent set of vectors of a space &lt;span class="math"&gt;\(X\)&lt;/span&gt; can be completed to form a basis for &lt;span class="math"&gt;\(X\)&lt;/span&gt;. This theorem is very important and we will be using it a lot.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Isomorphism of same dimension spaces&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Once we fix any basis for a space &lt;span class="math"&gt;\(X\)&lt;/span&gt; with dimension &lt;span class="math"&gt;\(n\)&lt;/span&gt;, every vector &lt;span class="math"&gt;\(x \in X\)&lt;/span&gt; can be represented by a &lt;span class="math"&gt;\(n\)&lt;/span&gt; tuple of scalars &lt;span class="math"&gt;\((k_1, \cdots k_n)\)&lt;/span&gt;. Using this representation, two different spaces &lt;span class="math"&gt;\(X\)&lt;/span&gt; and &lt;span class="math"&gt;\(Y\)&lt;/span&gt; of the same dimension are isomorphic to one another.&lt;/p&gt;
&lt;p&gt;Intuition - Any vector &lt;span class="math"&gt;\(y \in X\)&lt;/span&gt; can be written as &lt;span class="math"&gt;\(x = k_1x_1 + \cdots + k_nx_n\)&lt;/span&gt; where the &lt;span class="math"&gt;\(x\)&lt;/span&gt;s are the basis. here, the &lt;span class="math"&gt;\(k\)&lt;/span&gt;s form the tuple which defines the vector.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Linear Map&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A linear map &lt;span class="math"&gt;\(T\)&lt;/span&gt; from a vector space &lt;span class="math"&gt;\(X\)&lt;/span&gt; to another space &lt;span class="math"&gt;\(U\)&lt;/span&gt; (not necessarily of the same dimensions) is a function which takes input an &lt;span class="math"&gt;\(x \in X\)&lt;/span&gt; and gives the output &lt;span class="math"&gt;\(u \in U\)&lt;/span&gt;. As usual, &lt;span class="math"&gt;\(X\)&lt;/span&gt; is called the &lt;em&gt;domain&lt;/em&gt; of &lt;span class="math"&gt;\(X\)&lt;/span&gt; and &lt;span class="math"&gt;\(U\)&lt;/span&gt; is called the &lt;em&gt;target space&lt;/em&gt;. &lt;/p&gt;
&lt;p&gt;A linear map has the additional property&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Sums and (scalar) product of input maps to sums and (scalar) product of the outputs. i.e., &lt;span class="math"&gt;\(T(x+y) = T(x) + T(y)\)&lt;/span&gt; and &lt;span class="math"&gt;\(T(kx) = kT(x)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The image of &lt;span class="math"&gt;\(X\)&lt;/span&gt; under &lt;span class="math"&gt;\(T\)&lt;/span&gt; is also called the &lt;em&gt;range&lt;/em&gt; of T.&lt;/p&gt;
&lt;p&gt;Lets momentarily descend from the abstract world and to the world of matrices and relate the two.&lt;/p&gt;
&lt;p&gt;An &lt;span class="math"&gt;\(m \times n\)&lt;/span&gt; matrix is an example of a linear map &lt;span class="math"&gt;\(T\)&lt;/span&gt;, and a tuple of scalars in column format is an example of a vector &lt;span class="math"&gt;\(v\)&lt;/span&gt; &lt;/p&gt;
&lt;p&gt;A quick example is in order.&lt;/p&gt;
&lt;div class="math"&gt;$$T = 
\begin{bmatrix}
1 &amp;amp; 5 &amp;amp; 6 \\
2 &amp;amp; 7 &amp;amp; 9 
\end{bmatrix}, x = \begin{bmatrix}1 \\ 3 \\ 5\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;Then,&lt;/p&gt;
&lt;div class="math"&gt;$$y=T(x) = T \times x = \begin{bmatrix}28 \\ 43\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;Here, &lt;span class="math"&gt;\(T : X \mapsto U\)&lt;/span&gt;, where &lt;span class="math"&gt;\(X\)&lt;/span&gt; is a 3-dimension vector space and &lt;span class="math"&gt;\(U\)&lt;/span&gt; is a 2-dimensional vector space, and &lt;span class="math"&gt;\(x \in X\)&lt;/span&gt; and &lt;span class="math"&gt;\(y \in Y\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The following are some important properties of linear maps&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The value of the map on any given basis completely defines the map. This follows from the linearity property of the map&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In matrix form, multiplication on the right side by a column vector gives a column vector which is a linear combination of the columns of the matrix. By this interpretation, the column rank is equal to the dimension of the range of &lt;span class="math"&gt;\(T\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Quick example:&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$\begin{bmatrix}
\vdots &amp;amp; \vdots &amp;amp; \vdots \\
col1 &amp;amp; col2 &amp;amp; col3 \\
\vdots &amp;amp; \vdots &amp;amp; \vdots
\end{bmatrix} \cdot 
\begin{bmatrix}a\\b\\c\end{bmatrix} = \begin{bmatrix} \vdots \\ a\cdot col1 + b\cdot col2 + c\cdot col3 \\ \vdots \end{bmatrix}$$&lt;/div&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Similarly, multiplication from the left side by a row vector gives a row vector which is the linear combination of rows of the matrix. By this interpretation, the row rank is the dimension of the rowspace. &lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$\begin{bmatrix}a &amp;amp; b &amp;amp; c\end{bmatrix} \cdot \begin{bmatrix} 
\cdots &amp;amp; row1 &amp;amp; \cdots \\
\cdots &amp;amp; row2 &amp;amp; \cdots \\
\cdots &amp;amp; row3 &amp;amp; \cdots \\
\end{bmatrix} = \begin{bmatrix}\cdots &amp;amp; a\cdot row1 + b\cdot row2 + c\cdot row3 &amp;amp; \cdots\end{bmatrix}$$&lt;/div&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;range-nullspace theorem&lt;/strong&gt;: the set of all vectors &lt;span class="math"&gt;\(v \in X\)&lt;/span&gt; such that &lt;span class="math"&gt;\(T(v) = 0\)&lt;/span&gt; forms a subspace of &lt;span class="math"&gt;\(X\)&lt;/span&gt; and is called the nullspace &lt;span class="math"&gt;\(N_T\)&lt;/span&gt; of &lt;span class="math"&gt;\(T\)&lt;/span&gt;. We can show that &lt;span class="math"&gt;\(dim(X) = dim(R) + dim(N_T)\)&lt;/span&gt;. This is a very fundamental result.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Intuitive proof&lt;/strong&gt;: It is easy to show that the complement of &lt;span class="math"&gt;\(N_T\)&lt;/span&gt; is isomorphic to &lt;span class="math"&gt;\(R\)&lt;/span&gt;. &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Dot product or bilinear forms&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Once we choose a basis for a vector space, we can represent each vector by an element from &lt;span class="math"&gt;\(\mathbb{R}^n\)&lt;/span&gt;. Having done so, we can define a &lt;em&gt;dot product&lt;/em&gt; of two vectors, which produces a scalar in the usual way, for example&lt;/p&gt;
&lt;div class="math"&gt;$$\begin{bmatrix}a_1 &amp;amp; a_2 &amp;amp; a_3\end{bmatrix} \cdot \begin{bmatrix}b_1 \\ b_2 \\ b_3\end{bmatrix} = a_1b_1 + a_2b_2 + a_3b_3$$&lt;/div&gt;
&lt;p&gt;In abstract terms, it is possible to define the dot product without the need for basis vectors. It is done by defining a &lt;em&gt;dual&lt;/em&gt; vector space consisting of linear functions operating on the primal vector space. It can be shown that the dual and the primal vector space have the same dimensions.&lt;/p&gt;
&lt;p&gt;In concrete terms, when dealing with &lt;span class="math"&gt;\(\mathbb{R}^n\)&lt;/span&gt;, if the vectors of primal space are denoted by column vectors, the elements of the dual space can be considered to be represented by row vectors&lt;/p&gt;
&lt;p&gt;While solving linear equations, the row vectors typically arise as coefficients, and the column vectors arise as the unknowns. The coefficients are dual to the unknowns. This is in some sense reminiscent of the duality that is also encountered in linear programming.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Change of Basis&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;While dealing with &lt;span class="math"&gt;\(\mathbb{R}^n\)&lt;/span&gt;, when we don't explicitly specify the basis, we usually have in mind the &lt;strong&gt;standard basis&lt;/strong&gt;, which has a 1 in the &lt;span class="math"&gt;\(j^{th}\)&lt;/span&gt; position and zero everywhere else. Of course, there is nothing special about the standard basis, and any other basis can be used equally well. Suppose we want to use vectors &lt;span class="math"&gt;\(e_j\)&lt;/span&gt; where &lt;span class="math"&gt;\(j \in [1, n]\)&lt;/span&gt; as the basis, and suppose we want to convert between the old representation and the new representation, we can use a map which maps each old basis to its corresponding new basis. This is well defined, since a map is well defined if we specify the values on all the basis vectors. Furthermore, it is easy to see that this map is one-to-one. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Complement of a subspace&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;For every subspace &lt;span class="math"&gt;\(Y\)&lt;/span&gt; of space &lt;span class="math"&gt;\(X\)&lt;/span&gt;, there is a complementary subspace &lt;span class="math"&gt;\(Z\)&lt;/span&gt; of &lt;span class="math"&gt;\(X\)&lt;/span&gt; such that every vector &lt;span class="math"&gt;\(x \in X\)&lt;/span&gt; can be written &lt;em&gt;uniquely&lt;/em&gt; as &lt;span class="math"&gt;\(x = y + z\)&lt;/span&gt; where &lt;span class="math"&gt;\(y \in Y\)&lt;/span&gt; and &lt;span class="math"&gt;\(z \in Z\)&lt;/span&gt;. Furthermore, &lt;span class="math"&gt;\(dim\ X = dim\ Y + dim\ Z\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Intuition: consider a basis &lt;span class="math"&gt;\(y_1, \cdots, y_m\)&lt;/span&gt; for &lt;span class="math"&gt;\(Y\)&lt;/span&gt;. These can be completed by adding more linearly independent vectors &lt;span class="math"&gt;\(z_1, \cdots, z_n\)&lt;/span&gt; to form a full basis of &lt;span class="math"&gt;\(X\)&lt;/span&gt;. The subspace spanned by the &lt;span class="math"&gt;\(z\)&lt;/span&gt;s is the basis for &lt;span class="math"&gt;\(Z\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Some important points:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The complement of a subspace is not unique. There are many ways to complete the partial basis of &lt;span class="math"&gt;\(Y\)&lt;/span&gt;, and each different choice gives rise to a different complement&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A subspace and its complement are mutually exclusive, but &lt;em&gt;not&lt;/em&gt; collectively exhaustive, and as such, they do not partition the parent vector space. i.e., there can be vectors which are not present either in &lt;span class="math"&gt;\(Y\)&lt;/span&gt; or its complement. For example, if &lt;span class="math"&gt;\(x\)&lt;/span&gt; is decomposed as &lt;span class="math"&gt;\(y + z\)&lt;/span&gt; as above, with both components non-zero, then &lt;span class="math"&gt;\(x\)&lt;/span&gt; is neither in &lt;span class="math"&gt;\(Y\)&lt;/span&gt;, nor in its complement. Thus, it gives rise to 4 cases&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;y component&lt;/th&gt;
&lt;th&gt;z component&lt;/th&gt;
&lt;th&gt;location&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;the zero vector&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;non-zero&lt;/td&gt;
&lt;td&gt;in complement&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;non-zero&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;in subspace&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;non-zero&lt;/td&gt;
&lt;td&gt;non-zero&lt;/td&gt;
&lt;td&gt;as a direct-sum subset&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The direct-sum subset is &lt;em&gt;not&lt;/em&gt; a subspace. Example - the sum of the following two direct-sum vectors is not in the direct-sum: &lt;span class="math"&gt;\((y+z), (y-z)\)&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Orthogonal complement&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;There is however, one unique complement called the orthogonal complement. In the same notation as above, suppose &lt;span class="math"&gt;\(Z\)&lt;/span&gt; is an orthogonal complement. then &lt;span class="math"&gt;\(\forall y \ \ \forall z, \ \  y \cdot z = 0\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;In abstract language, the orthogonal complement is a subset of the dual space, and it is usually called the annihilator of &lt;span class="math"&gt;\(Y\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Note that, all the other properties of complements are still true for orthogonal complements.&lt;/p&gt;
&lt;p&gt;In particular, &lt;span class="math"&gt;\(dim\ X = dim\ Y + dim\ Z\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;This fact is so important, but it is not usually part of the standard fare, that I will give the outline of a proof here.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Theorem&lt;/strong&gt;: Let &lt;span class="math"&gt;\(X\)&lt;/span&gt; be &lt;span class="math"&gt;\(\mathbb{R}^n\)&lt;/span&gt;, so &lt;span class="math"&gt;\(dim(X) = n\)&lt;/span&gt;. Let &lt;span class="math"&gt;\(Y\)&lt;/span&gt; be a subspace of &lt;span class="math"&gt;\(X\)&lt;/span&gt;, spanned by &lt;span class="math"&gt;\(v_1, \cdots, v_r\)&lt;/span&gt;. &lt;span class="math"&gt;\(dim(Y)=r\)&lt;/span&gt;, then the orthogonal complement &lt;span class="math"&gt;\(Z\)&lt;/span&gt; has &lt;span class="math"&gt;\(dim(Z) = n-r\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proof&lt;/strong&gt;: We will establish a 1:1 mapping between &lt;span class="math"&gt;\(Z\)&lt;/span&gt; and &lt;span class="math"&gt;\(\mathbb{R}^{n-r}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;First complete the partial basis of &lt;span class="math"&gt;\(Y\)&lt;/span&gt; to get a full basis &lt;span class="math"&gt;\(v_1, \cdots, v_n\)&lt;/span&gt;. Let &lt;span class="math"&gt;\(z \in Z\)&lt;/span&gt;. Define the mapping &lt;span class="math"&gt;\(T:z \mapsto z'\)&lt;/span&gt; where &lt;/p&gt;
&lt;div class="math"&gt;$$z' = [0, 0, \cdots, 0, z\cdot v_{r+1}, \cdots, z\cdot v_n]$$&lt;/div&gt;
&lt;p&gt;Any such &lt;span class="math"&gt;\(z'\)&lt;/span&gt; also maps back to a unique &lt;span class="math"&gt;\(z \in Z\)&lt;/span&gt; by &lt;span class="math"&gt;\(z \cdot v_i = z'[i]\)&lt;/span&gt;. Here we use the fact that a vector is uniquely specified by its values on the dot product on the basis vectors&lt;/p&gt;
&lt;p&gt;In abstract language, the orthogonal complement is called annihilator and represented as a subspace of the dual space (remember that the dual space is a space of all bilinear functions). The proof of dimension usually involves proving an isomorphism between the annihilator and the dual of the quotient space &lt;span class="math"&gt;\((X/Y)\)&lt;/span&gt;. Effectively quotient space of a subspace is what you get by throwing away components of the basis of the subspace. i.e., the "rest" of the space apart from the subspace. &lt;/p&gt;
&lt;p&gt;Although the proof looks much cleaner there, I find the vesion I presented here to be more clear conceptually, where we establish an isomorphism between annihilator and &lt;span class="math"&gt;\(z' = [0, 0, \cdots, 0, z\cdot v_{r+1}, \cdots, z\cdot v_n]\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Rowspace, columnspace and nullspace of a matrix&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The rows and columns of a matrix can be considered to be vectors. An &lt;span class="math"&gt;\(m \times n\)&lt;/span&gt; matrix has &lt;span class="math"&gt;\(m\)&lt;/span&gt; row vectors of dimension &lt;span class="math"&gt;\(n\)&lt;/span&gt; and &lt;span class="math"&gt;\(n\)&lt;/span&gt; column vectors of dimension &lt;span class="math"&gt;\(m\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The rowspace is the subspace spanned by rows, and similarly for column space. The nullspace is the set of input vectors that maps to 0 vector under &lt;span class="math"&gt;\(T\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The row/column rank of a matrix is defined as the max number of linearly independent rows/columns.&lt;/p&gt;
&lt;p&gt;We are now in a position to restate the rank theorem&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The rank theorem&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The row rank of a matrix is the same as the column rank. i.e., the number of linearly independent rows in a matrix is equal to the number of linearly independent columns in the matrix&lt;/p&gt;
&lt;h1&gt;The surprising nature of the rank theorem&lt;/h1&gt;
&lt;p&gt;Consider any matrix of any size, say &lt;span class="math"&gt;\(100 \times 1000\)&lt;/span&gt;, filled with random numbers. &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;There are 100 row vectors each of dimension 1000. The rows vectors look like &lt;span class="math"&gt;\((x_1, x_2, \cdots, x_{1000})\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;And there are 1000 column vectors, each of dimension 100. The column vectors look like &lt;span class="math"&gt;\((y_1, y_2, \cdots, y_{100})\)&lt;/span&gt;. &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The row vectors look very different from the column vectors. Looking individually, the numbers also seem to bear no relationship to each other. Even the dimensions do not match. And yet, the rank theorem asserts that if there are only 50 linearly independent rows, then there will only be 50 linearly independent columns amongst the 1000.&lt;/p&gt;
&lt;p&gt;Another example: Consider the following matrix&lt;/p&gt;
&lt;div class="math"&gt;$$T = 
\begin{bmatrix}
1 &amp;amp; 5 &amp;amp; 6 \\
2 &amp;amp; 7 &amp;amp; 9 \\
3 &amp;amp; 6 &amp;amp; 1 \\
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;Here, all the three rows are linearly independent, as are all the columns. However, I have made the column &lt;span class="math"&gt;\(C_3\)&lt;/span&gt; "just miss" to be equal to &lt;span class="math"&gt;\(C_1 + C_2\)&lt;/span&gt;. (&lt;span class="math"&gt;\(3+6 \ne 1\)&lt;/span&gt;). If I change that one number &lt;span class="math"&gt;\(x_{33}\)&lt;/span&gt; from 1 to 9, there are only 2 linearly independent columns. Now the rank theorem asserts that this change has forced one of the rows also to be linearly dependent on the other two rows. Yet, I am hard pressed to find out what is that linear combination by visual inspection. Can you spot the linear relationship between rows &lt;span class="math"&gt;\(R_1, R_2, R_3\)&lt;/span&gt;?&lt;/p&gt;
&lt;p&gt;i.e., given &lt;span class="math"&gt;\(R_1 = [1, 5, 6]\)&lt;/span&gt;, &lt;span class="math"&gt;\(R_2 = [2, 7, 9]\)&lt;/span&gt; and &lt;span class="math"&gt;\(R_3 = [3, 6, 9]\)&lt;/span&gt;, can you find three numbers &lt;span class="math"&gt;\(a, b, c\)&lt;/span&gt; (not all zero) such that &lt;span class="math"&gt;\(aR_1 + bR_2 + cR_3 = 0\)&lt;/span&gt; by visual inspection? The rank theorem guarantees its existence, and indeed, &lt;span class="math"&gt;\(3R_1 - 3R_2 + R_3 = 0\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Lets look at the previous example a bit more closely. Suppose&lt;/p&gt;
&lt;div class="math"&gt;$$T = 
\begin{bmatrix}
a &amp;amp; d &amp;amp; a+d \\
b &amp;amp; e &amp;amp; b+e \\
c &amp;amp; f &amp;amp; c+f \\
\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;So that &lt;span class="math"&gt;\(C_3 = C_1 + C_2\)&lt;/span&gt; and lets try to solve generally for &lt;span class="math"&gt;\(xR_1 + yR_2 + zR_3 = 0\)&lt;/span&gt;. Can you guess the values for &lt;span class="math"&gt;\(x, y, z\)&lt;/span&gt; from visual inspection? I certainly couldn't! We can use standard techniques (from linear algebra itself, of course!) to find &lt;/p&gt;
&lt;div class="math"&gt;$$\begin{eqnarray}
x &amp;amp;= bf - ce \\
y &amp;amp;= dc - af \\
z &amp;amp;= ae - bd 
\end{eqnarray}$$&lt;/div&gt;
&lt;p&gt;To me, it is surprising that a simple relationship between columns translates to such a complicated relationship among the rows. Now if you consider a &lt;span class="math"&gt;\(1000 \times 1000\)&lt;/span&gt; matrix with a complicated relationship among the columns, one can only imagine how complicated the relationship between the rows will be, and yet, the rank theorem guarantees that such a relationship must exist!&lt;/p&gt;
&lt;p&gt;Having thus shown how surprising the result of the theorem is, I want to present a somewhat intuitive proof of the theorem.&lt;/p&gt;
&lt;h1&gt;An intuitive proof&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Transpose&lt;/strong&gt; of a matrix is the matrix obtained by swapping its rows and columns&lt;/p&gt;
&lt;p&gt;Let &lt;span class="math"&gt;\(T: X \mapsto U\)&lt;/span&gt; be a linear map and &lt;span class="math"&gt;\(m \times n\)&lt;/span&gt; matrix. So &lt;span class="math"&gt;\(dim(X) = n\)&lt;/span&gt; and &lt;span class="math"&gt;\(dim(U) = m\)&lt;/span&gt;. Let &lt;span class="math"&gt;\(T'\)&lt;/span&gt; be its transpose. Let &lt;span class="math"&gt;\(R \subset U\)&lt;/span&gt; be the range of &lt;span class="math"&gt;\(T\)&lt;/span&gt;, with &lt;span class="math"&gt;\(dim(R)=r\)&lt;/span&gt;. So the dimension of columnspace is &lt;span class="math"&gt;\(r\)&lt;/span&gt;. And we need to show that the dimension of rowspace of &lt;span class="math"&gt;\(T\)&lt;/span&gt; (which is dimension of colspace of &lt;span class="math"&gt;\(T'\)&lt;/span&gt;) = &lt;span class="math"&gt;\(r\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(R\)&lt;/span&gt; has a orthogonal complement &lt;span class="math"&gt;\(S\)&lt;/span&gt;, with &lt;span class="math"&gt;\(dim(S)=m-r\)&lt;/span&gt;. let &lt;span class="math"&gt;\(s \in S\)&lt;/span&gt;. Now &lt;span class="math"&gt;\(s\)&lt;/span&gt; kills every vector in &lt;span class="math"&gt;\(R\)&lt;/span&gt;, which are nothing but linear combinations of columns of &lt;span class="math"&gt;\(T\)&lt;/span&gt;, and hence in matrix form, we can write&lt;/p&gt;
&lt;div class="math"&gt;$$\begin{bmatrix} 
\cdots &amp;amp; col1 &amp;amp; \cdots \\
\cdots &amp;amp; col2 &amp;amp; \cdots \\
\cdots &amp;amp; coln &amp;amp; \cdots \\
\end{bmatrix} \cdot s = 0$$&lt;/div&gt;
&lt;p&gt;Observe that here, the columns have become rows, and it is actually the transpose matrix &lt;span class="math"&gt;\(T'\)&lt;/span&gt;. Thus it is clear that &lt;span class="math"&gt;\(s \in N_{T'}\)&lt;/span&gt; where &lt;span class="math"&gt;\(N_{T'}\)&lt;/span&gt; is the nullspace of &lt;span class="math"&gt;\(T'\)&lt;/span&gt;. So, &lt;span class="math"&gt;\(S = N_{T'}\)&lt;/span&gt; and thus &lt;span class="math"&gt;\(dim(N_{T'}) = m-r\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Applying the range-nullspace theorem to &lt;span class="math"&gt;\(T'\)&lt;/span&gt;, immediately gives the dimension of the range of &lt;span class="math"&gt;\(T'\)&lt;/span&gt; as &lt;span class="math"&gt;\(dim(R_{T'}) = r\)&lt;/span&gt;. This is what we wanted to prove.&lt;/p&gt;
&lt;p&gt;Leaving the mathematics aside, lets try to describe in words what is happening. Consider a &lt;span class="math"&gt;\(n \times n\)&lt;/span&gt; matrix with all rows and columns independent. Now lets see what happens when we make one of the columns to be linearly dependent on the other columns.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The columns fail to span the full space of &lt;span class="math"&gt;\(U\)&lt;/span&gt;, and thus the range of &lt;span class="math"&gt;\(T\)&lt;/span&gt; decreases by 1.&lt;/li&gt;
&lt;li&gt;This gives rise to an orthogonal complement subspace in U, with the dimension of 1&lt;/li&gt;
&lt;li&gt;Since a vector &lt;span class="math"&gt;\(z\)&lt;/span&gt; in the orthogonal complement kills every vector in the range of &lt;span class="math"&gt;\(T\)&lt;/span&gt;, it actually provides a linear combination between the rows of &lt;span class="math"&gt;\(T\)&lt;/span&gt;. Just re-iterating this step in math: &lt;/li&gt;
&lt;/ol&gt;
&lt;div class="math"&gt;$$\begin{eqnarray}z \cdot c_1  &amp;amp;= 0 \\
z \cdot c_2 &amp;amp;= 0 \\
&amp;amp;\vdots \\
z \cdot c_n &amp;amp;= 0 \\
\implies z \cdot \begin{bmatrix}c_1 &amp;amp; \cdots &amp;amp; c_n\end{bmatrix} &amp;amp;= z \cdot T = 0\end{eqnarray}$$&lt;/div&gt;
&lt;p&gt;.
Remember that left multiplication by a row vector is equivalent to a linear combination of the rows. So the last equation is saying that there is a lienar combination of rows that gives 0, which means that the rows are not linearly independent! Thus, In this way, we see how a linear combination of columns have forced a linear combination of rows.&lt;/p&gt;
&lt;p&gt;Now, we will briefly explore some other common proofs
:&lt;/p&gt;
&lt;h1&gt;Proof using elementary operations&lt;/h1&gt;
&lt;p&gt;This is the most common proof&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;elementary row operations&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;There are 3 such elementary row operations&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;swap two rows of a matrix&lt;/li&gt;
&lt;li&gt;add another row to current row&lt;/li&gt;
&lt;li&gt;multiply current row by a scalar&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The proof proceeds in the following steps&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Show that each elementary row operation corresponds to multiplying by an elementary matrix that is invertible&lt;/li&gt;
&lt;li&gt;Show that multiplying by an elementary matrix has the following effects&lt;ol&gt;
&lt;li&gt;Rowspace - unchanged, because the row operations are simply linear combinations of other rows&lt;/li&gt;
&lt;li&gt;nullspace - unchanged, because, if &lt;span class="math"&gt;\(ET(x) = 0\)&lt;/span&gt; iff &lt;span class="math"&gt;\(T(x) = 0\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;columnspace - changed, but preserves linear combinations. short proof - suppose &lt;span class="math"&gt;\(c_x\)&lt;/span&gt; are the columns, and suppose &lt;span class="math"&gt;\(a_1c_1 + \cdots + a_nc_n = 0\)&lt;/span&gt;, then 
&lt;div class="math"&gt;$$a_1c_1 + \cdots + a_nc_n =  
\begin{bmatrix}
c1 &amp;amp; \cdots &amp;amp; c_n\end{bmatrix}\begin{bmatrix}
a1 \\ \vdots \\ a_n\end{bmatrix} = 0$$&lt;/div&gt;. So &lt;div class="math"&gt;$$\begin{bmatrix}
a1 \\ \vdots \\ a_n\end{bmatrix}$$&lt;/div&gt; is in the nullspace of &lt;span class="math"&gt;\(T\)&lt;/span&gt; and thus also in the nullspace after the elementary row operation&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Use the elementary row operations to arrive at the &lt;a href="https://en.wikipedia.org/wiki/Row_echelon_form#Reduced_row_echelon_form"&gt;&lt;em&gt;reduced row echelon form&lt;/em&gt;&lt;/a&gt; &lt;span class="math"&gt;\(rref(T)\)&lt;/span&gt;, from which you can just visually see that the row rank and column rank are equal&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This proof is actually pretty elegant, especially when it shows that the column space does not change under elementary row operations. However, I don't find it very clear why a linear dependence on the rows/columns should induce a corresponding linear dependence on the column/rows &lt;/p&gt;
&lt;h1&gt;A small improvement of the above proof&lt;/h1&gt;
&lt;p&gt;The following improvement perhaps cuts more directly to the issue at hand.&lt;/p&gt;
&lt;p&gt;Let &lt;span class="math"&gt;\(c_1, \cdots, c_r\)&lt;/span&gt; be independent column vectors in the matrix &lt;span class="math"&gt;\(T\)&lt;/span&gt; In the target space U, the basis is the &lt;a href="https://en.wikipedia.org/wiki/Standard_basis"&gt;standard basis&lt;/a&gt;. Perform a change of basis by choosing the linearly independent column vectors as a partial basis, and complete them to get a full basis. This &lt;a href="https://en.wikipedia.org/wiki/Change_of_basis"&gt;change of basis&lt;/a&gt; can be represented as another invertible matrix &lt;span class="math"&gt;\(S:U \mapsto V\)&lt;/span&gt;, where &lt;span class="math"&gt;\(V\)&lt;/span&gt; is another vector space of the same dimensions. Now consider the matrix &lt;span class="math"&gt;\(Q : X \mapsto V \stackrel{\text{def}}{=} S \cdot T\)&lt;/span&gt;. It is easy to see that 
Q is of the following form
&lt;/p&gt;
&lt;div class="math"&gt;$$Q = \begin{bmatrix}
 I &amp;amp; X \\ 
 0 &amp;amp; 0\end{bmatrix}$$&lt;/div&gt;
&lt;p&gt;
 Since &lt;span class="math"&gt;\(S\)&lt;/span&gt; is invertible, &lt;span class="math"&gt;\(Q\)&lt;/span&gt; and &lt;span class="math"&gt;\(T\)&lt;/span&gt; have the same rowspace, nullspace, and preserves linear combinations on the column space. And from this matrix, it is easy to see that the row rank is equal to the column rank&lt;/p&gt;
&lt;p&gt;There are two other less well known proofs, and I really like them, and can't help but mention one of these proofs. Both of these are mentioned on this &lt;a href="https://proofwiki.org/wiki/Column_Rank_of_Matrix_equals_Row_Rank"&gt;webpage&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;Proof using orthogonality&lt;/h1&gt;
&lt;p&gt;It proceeds by the following steps&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Prove that linearly independent rows are mapped to linearly independent columns (really clever!)&lt;/li&gt;
&lt;li&gt;this proves that $rowrank &amp;lt;= column rank&lt;/li&gt;
&lt;li&gt;Apply the same method to the transpose, giving columnrank &amp;lt;= rowrank&lt;/li&gt;
&lt;li&gt;hence rowrank=columnrank!&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So there you go! I hope these different viewpoints of looking at a fundamental result helps in a deeper understanding. It also shows such a rich structure for linear combinations. Keep on combining linearly!&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="misc"></category><category term="misc"></category></entry><entry><title>The choice of programming languages</title><link href="/the-choice-of-programming-languages.html" rel="alternate"></link><published>2021-10-10T22:20:00+00:00</published><updated>2021-10-10T22:20:00+00:00</updated><author><name>Sharath Gururaj</name></author><id>tag:None,2021-10-10:/the-choice-of-programming-languages.html</id><summary type="html">&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Thanks to advances in compiler technologies, Programmers today are spoilt for choice with the myriad of mainstream programming languages available your next big idea. However, the landscape can quickly get confusing. Many different languages seem to offer the same features and generally "looks the same". Consider the website description …&lt;/p&gt;</summary><content type="html">&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Thanks to advances in compiler technologies, Programmers today are spoilt for choice with the myriad of mainstream programming languages available your next big idea. However, the landscape can quickly get confusing. Many different languages seem to offer the same features and generally "looks the same". Consider the website description of two languages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Kotlin: "A modern programming language
  that makes developers happier."&lt;/li&gt;
&lt;li&gt;Swift: "Swift is a general-purpose programming language built using a modern approach to safety, performance, and software design patterns."&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You get the idea.&lt;/p&gt;
&lt;p&gt;Young programmers with the next brilliant idea for a startup often pick languages for no more reason than the fact that its the "cool kid on the block".&lt;/p&gt;
&lt;p&gt;This blog tries to throw some light on the factors you should consider while picking a language.&lt;/p&gt;
&lt;h1&gt;Language features&lt;/h1&gt;
&lt;p&gt;Before we get to the languages themselves, let us briefly review some key terminology relating to language features&lt;/p&gt;
&lt;h2&gt;Target language&lt;/h2&gt;
&lt;p&gt;There are three major types &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Compiled to Native: This means that the compiler generates machine code that can be directly executed by the CPU. Example C, C++, Rust, Go&lt;/li&gt;
&lt;li&gt;Compiled to bytecode: This means that the compiler compiles to a intermediate "low level" language,  which then requires an interpreter. Example: Java compiles down to "bytecode" which is then interpreted by the jvm during execution.&lt;/li&gt;
&lt;li&gt;Interpreted: No separate compilation step is necessary. The language source code is interpreted "on the fly" by an interpreter. For example, python, javascript&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note that some languages offer multiple targets. For example, kotlin can be compiled both to bytecode as well as native. But they are usually popular only  in one particular mode. For example, kotlin is usually compiled to bytecode.&lt;/p&gt;
&lt;h2&gt;Static typed vs dynamic typed&lt;/h2&gt;
&lt;p&gt;Statically typed means that the type of every variable is known during compile time. This generally means that we need to specify the type of the variable while declaring the vaiable. For example, in java &lt;code&gt;String name;&lt;/code&gt;. The variable &lt;code&gt;name&lt;/code&gt; cannot hold anything other than a &lt;code&gt;String&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;In contrast, In dynamic typed languages, the type of variables is not known to compilers and no such type declaration is necessary for variables. For example in python, The following is possible&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# amount is a string&lt;/span&gt;
&lt;span class="n"&gt;amount&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;2&amp;quot;&lt;/span&gt; 

&lt;span class="c1"&gt;# amount is a number&lt;/span&gt;
&lt;span class="n"&gt;amount&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Static typed languages are more verbose compared to dynamic typed languages. But they are much easier to refactor, and eliminate a large class of programming errors at compile time. Static languages are also much more IDE friendly. This is because IDE tooling can easily figure out valid methods for auto complete. Once the codebase and the team grows larger, static typing makes the codebase easier to learn for new joinees, and easier to refactor.&lt;/p&gt;
&lt;h1&gt;Garbage collection&lt;/h1&gt;
&lt;p&gt;There are 3 main classes of languages:&lt;/p&gt;
&lt;h2&gt;Automatic garbage collection&lt;/h2&gt;
&lt;p&gt;These programming languages track references to variables and can automatically free the memory when a variable is no longer used. Example: java, python, javascript, go&lt;/p&gt;
&lt;h2&gt;Garbage collection by reference counting&lt;/h2&gt;
&lt;p&gt;In some programming languages, there is no built in garbage collection, but rather, the language offers standard libraries that can ease memory management. These libraries typically work by maintaining reference counters which automatically get incremented on an assignment, or decrementd when a variable goes out of scope. When properly used, these languages feel almost like true garbage collected languages, without the runtime overhead of an actual garbage collector. For example, &lt;code&gt;unique_ptr&lt;/code&gt; in C++ offers such capabilities.&lt;/p&gt;
&lt;p&gt;In other languages, such reference counting is built-in to the language itself. Thus, memory allocation is always "safe", and yet there is no separate garbage collection component. For example: rust.&lt;/p&gt;
&lt;h2&gt;No garbage collection&lt;/h2&gt;
&lt;p&gt;Low level languages like C offer no GC.&lt;/p&gt;
&lt;h1&gt;Threading support&lt;/h1&gt;
&lt;h2&gt;Support through standard libraries&lt;/h2&gt;
&lt;p&gt;Some languages have no built-in support for threads, but offer standard libraries which allows us to create native threads. For example, C, C++&lt;/p&gt;
&lt;h2&gt;Language support for threads&lt;/h2&gt;
&lt;p&gt;Some languages offer language native syntax for paralellism and threads and come with strong memory models. For example, Java, Go, Rust. In the case of C++, although there is no language support for threads, it does have a well defined memory model. Sometimes, the language itself offers an abstraction of threads, which may or maynot correlate to operating system threads. For example, Go offers "green threads", which are supposedly more lightweight than OS threads. These green threads are managed by the language runtime and do no directly correspond to OS threads. For example, n green threads can be mapped to m OS threads.&lt;/p&gt;
&lt;h2&gt;Very little or no language support&lt;/h2&gt;
&lt;p&gt;Python and Javascript are examples. In the case of python, there is a "Global interpreter lock" which effectively kills any possibility for true multi threading. In the case of Javascript, the language design constraints it to be single-threaded. More on this later.&lt;/p&gt;
&lt;p&gt;Having covered the salient language features of interest, let us know discuss specific languages&lt;/p&gt;
&lt;h1&gt;Java&lt;/h1&gt;
&lt;p&gt;Java is a bytecode-compiled, static-typed, garbage collected language with built-in thread support which maps directly to operating system threads. Java should be your go-to general purpose language for any project that lasts more than a few months.&lt;/p&gt;
&lt;p&gt;Java has a reputation to be &lt;a href="http://steve-yegge.blogspot.com/2006/03/execution-in-kingdom-of-nouns.html"&gt;very verbose&lt;/a&gt; But this is not a problem with the language itself, but rather with the conventions that have come to be associated with the langauge. For example, for "value objects" go ahead and skip the setters and getters and directly use public variables. It is easy to refactor it later with the help of IDE if the need arises.&lt;/p&gt;
&lt;p&gt;Java is sometimes castigated for the arbitrary stop-the-world garbage collection pauses. But in my experience, if you're running into this problem, there is probably a bug which is causing excessive temporary objects to be created. The garbage collector can easily collect several 10s of GB of garbage per second.&lt;/p&gt;
&lt;p&gt;Although Java is an bytecode interpreted language, it is no slouch when compared to performance. Java speed can be expected to be around 70% to 90% of the speed of C/C++, the runtime safety offered by the JVM far outweighs the performance hit.&lt;/p&gt;
&lt;h2&gt;What is Java good for&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Web applications: Java has library support for epoll system calls, which makes it good for serving CDN and static content. The good thread support can make effective use of todays multi-core CPUs&lt;/li&gt;
&lt;li&gt;Large enterprise projects. The static typing enables very intelligent IDE support and makes refactoring easy. As long as you keep your code simple, (don't create BS classes like &lt;code&gt;Delegator, ResourceManager, blah blah&lt;/code&gt;) Java will be your friend for years to come. &lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Python&lt;/h1&gt;
&lt;p&gt;Python is a dynamic typed, interpreted, garbage collected language with very little thread support.&lt;/p&gt;
&lt;p&gt;Python is a favorite for many programmers and is highly adopted in enterprise software as well as startups for their implementation. This, I think is a major mistake, which causes no end of troubles later on. Here are some reasons&lt;/p&gt;
&lt;h2&gt;Speed&lt;/h2&gt;
&lt;p&gt;Python is &lt;strong&gt;dead slow&lt;/strong&gt;. Python can be expected to be about &lt;strong&gt;20-100 times slower&lt;/strong&gt; than Java or C/C++. If you want to see it for yourself, just implement this simple program in various languages and time the execution.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;count&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;100000000&lt;/span&gt;
    &lt;span class="n"&gt;count&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Maintenance&lt;/h2&gt;
&lt;p&gt;Python is dynamic typed. Python looks pretty in the beginning, but as the project grows, the lack of static typing will really bite you. Code gets harder to refactor. New joinees take longer to understand the contracts, Subtle corner cases are introduced, etc. Soon you'll be introducing bugs as fast as you fix them.&lt;/p&gt;
&lt;h2&gt;Lack of thread support&lt;/h2&gt;
&lt;p&gt;As we all know, processor speeds have stopped increasing for almost a decade now. Moore's law is now seen in the core count, rather than the clock speed. In this age of multi-core, do you really want to choose a language which has almost no threading support? The global interpreter lock all but prevents use of multi-core CPUs. This makes python especially bad as a language for web servers, and yet, paradoxically, it is a popular choice for web servers. &lt;/p&gt;
&lt;h2&gt;What is python is good for&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;As a replacement for bash scripts. This is because, readability matters more than speed, and the script size is small&lt;/li&gt;
&lt;li&gt;For small throw-away projects. Maybe, you want to quick filter a log file, or do some small string manipulation. Python is perfect for these, where you don't want static typing to get in the way&lt;/li&gt;
&lt;li&gt;For &lt;strong&gt;interactive programming&lt;/strong&gt;. For example, in data science, we are exploring data, we need to quickly try out many different things. Furthermore, we don't want to recompute intermediate data everytime. The python REPL is very useful for this kind of programming.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Avoid python for&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Web server and backend code. There is no multi threading support, pssh.&lt;/li&gt;
&lt;li&gt;Long lived software: The maintenance cost in the long run is much higher than static typed languages&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Javascript&lt;/h1&gt;
&lt;p&gt;Hoo boy, where to start? Let's start with a brief history. From the beginning, Javascript was designed and implemented to run on browsers. It started its life as a hacky scripting language, with equal parts good and bad, which lead to &lt;a href="https://www.oreilly.com/library/view/javascript-the-good/9780596517748/"&gt;books like these&lt;/a&gt;. Later, google arrived on the scene, with plans for their own chrome browser in 2004. As part of the browser, Google of course needed a good javascript interpreter and virtual machine. In 2004, they hired Lars Bak, gave him a big pile of money and sent him to a cave in Denmark, and asked him not to emerge until he had a world class js interpretor. As a result, he created precisely that: the v8 javascript virtual machine. Fast forward 2009, Ryan dahl get the idea to rip out the v8 engine from chrome, and run it as a standalone virtual machines with a good enough runtime library, and node.js was born.&lt;/p&gt;
&lt;p&gt;Meanwhile, javascript: the language itself underwent a massive upheaval in the the of ECMAScript 6 specification. It cleaned up a lot of the syntax and enabled basic modular packaging capabilities.
The architecture of Javascript reflects its origins in the bowels of the  browser. Here it is heavily used almost as a event driven programming language, primarily to drive the GUI. For example, "on click of submit button, send a request to the server and fetch some data". Historically, there have been many attempts at a multi-threaded graphics library, but all thus far have been doomed to fail. Multi threaded even driven programming is notoriously hard.&lt;/p&gt;
&lt;p&gt;Thus, by design, Javascript in its very nature is single threaded. The virtual machine maintains an "event queue". All javascript code executes in response to events in a single thread. Thus, coding in javascript leads to callback hell.&lt;/p&gt;
&lt;p&gt;This has the very important consequence that if usercode blocks the single thread, (or example, maybe you're running some heavy encryption algorithm), then the entire event queue effectively gets blocked.&lt;/p&gt;
&lt;p&gt;Proponents of node.js will point to one advantage that is quite popular.
The node.js eventing engine is implemented using &lt;a href="https://github.com/libuv/libuv"&gt;libuv&lt;/a&gt; which uses native asynchronous I/O (for example, the &lt;code&gt;epoll&lt;/code&gt; system call in linux) to avoid allocating a thread for each event. Although this is true, the real world benefits come with a lot of caveats that we'll cover shortly.&lt;/p&gt;
&lt;h2&gt;Why you should never use node.js for the backend&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The asynchronous coding still is simply not how the human brain works. There are better things to do in life than debug a deeply nested asynchronous callback hell&lt;/li&gt;
&lt;li&gt;The single threaded nature of V8 means that&lt;ul&gt;
&lt;li&gt;Its very difficult to exploit todays multicore CPU architectures&lt;/li&gt;
&lt;li&gt;You have to take great care to make sure you don't block the main thread. Doing this will cause huge queueing delays for all other users&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The asynchronous I/O bit is more hype than real usefulness. Modern linux kernel threads are lightweight enough to switch thousands of threads without any noticeable context switching overhead. For example, these days, the linux kernel can switch thread context in a couple of hundred nanoseconds. The asynchronous IO maybe useful in some niche use cases such as CDN serving. However, in this case, there are much better native implementations, for example nginx. Asynchronous IO is only really useful when you have hundreds of thousands of connections, all of which  are mostly idle. In the real world, this is rarely the case.&lt;/li&gt;
&lt;li&gt;All the other bad things that come as part of being a dynamic typed language (see the section on python)&lt;/li&gt;
&lt;li&gt;Although the recent ECMAScript specifications have improved the language a lot, there is a bit chunk of a &lt;a href="https://medium.com/@Rewieer/javascript-the-bad-parts-and-how-to-avoid-them-1a7c9bc5a0dd"&gt;bad part&lt;/a&gt;, much bigger than other programming languages&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thus, the bottomline is that if you're coding for the browser, there is no escaping javascript. But if you're coding for a backend, it seems there is never really a justification to use javascript or node.js. You're better off using python or java&lt;/p&gt;
&lt;h1&gt;Languages for System programming&lt;/h1&gt;
&lt;p&gt;By system programming, we mean access to low level machine features, such as pointers, or the memory layout of datastructures, or special purpose CPU instructions, or low level kernel APIs etc. For example, perhaps, you're building a database, and you need precise control over the header of your data files. System programming also places a premium on performance, often trying to extract every last bit of juice from the hardware.&lt;/p&gt;
&lt;p&gt;System programming languages usually have the following features. They are statically typed and compiles to native code. &lt;/p&gt;
&lt;h2&gt;C/C++&lt;/h2&gt;
&lt;p&gt;We need no introduction to these languages here. Everything from operating systems to databases have been built with these languages. However we should talk about why people found the need to invent new system programming languages&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;C/C++ compilation is slow. This is because the &lt;code&gt;#include&lt;/code&gt; in each file makes compilation reuse very difficult. This is fine if the headers only contain declarations, but the recursive nature of headers means that even one bad header will propagate everywhere. &lt;/li&gt;
&lt;li&gt;No garbage collection. Usually, a full-featured garbage collector is frowned upon in system programming languages, because there needs to be tight and predictable performance bounds for the running code. It is often unacceptable for the program to "freeze" because of a running garbage collector. However, it is possible to build deterministic garbage collection using some common techniques, such as incrementing a hidden reference count on variable assignment and decrementing the count in the object destructor. For example C++ offers the so called &lt;code&gt;smart pointers&lt;/code&gt; which automatically manage the lifecycle of the underlying objects. However, built-in language support would always be a welcome feature&lt;/li&gt;
&lt;li&gt;No language support for threading and concurrency. Although C++ now has a well defined threading library and a memory model, having builtin threading support can make programming much simpler, for example using go &lt;code&gt;channels&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Obsolete syntax: C and C++ are well over 30 years old, and advancements in compiler technologies enables much cleaner syntax in a modern language&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;When should you use C/C++&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;If you're doing system programming, C/C++ is still an excellent choice.&lt;/li&gt;
&lt;li&gt;If you place an extreme premium on performance, C/C++ offers best in class performance. However, other languages such as go and rust can offer equally good performance with a much cleaner syntax&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Go&lt;/h1&gt;
&lt;p&gt;Go is a statically typed, native compiled, garbage collected language with built-in support for concurrency.
Go was created at google over the many frustrations faced with C++. It offers fast compilation speeds with a full featured garbage collector as well as language syntax for built in concurrency.&lt;/p&gt;
&lt;h2&gt;When should you use go&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;If you're doing system programming, but would like to make your life easier with a cleaner syntax, garbage collection and builtin concurrency, go for go. &lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Rust&lt;/h1&gt;
&lt;p&gt;Rust is a statically typed, native compiled, deterministic garbage collected language with built in thread support. 
Both go and rust offer a much cleaner syntax compared to C/C++. The main differences between Go and Rust are the following&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The Go garbage collector runs as a separate thread, and is non deterministic (i.e., you don't know when it will run and for how long), much similar to the java garbage collector. However rust uses a deterministic garbage collector similar to the smart pointer mechanism in C++&lt;/li&gt;
&lt;li&gt;Go threads are "green" threads, managed by the Go runtime, and may not correspond one-to-one with system threads, whereas rust threads are true system threads&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;When should you use Rust&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;If you're doing system programming, but would like to make your life easier with a cleaner syntax, a deterministic garbage collector and low level concurrency control, use rust. &lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Julia vs Python: The sad state of data science today&lt;/h1&gt;
&lt;p&gt;We will end this blog with a note on the current sad state of data science&lt;/p&gt;
&lt;p&gt;Data Science has some unique requirements that has challenged the limits of compiler technology&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Often data scientists are precisely that: scientists. They are not well versed with programming languages. A simple syntax would be much preferable&lt;/li&gt;
&lt;li&gt;The need for a REPL: The day of a data scientist begins and ends with the REPL. This exploratory programming is an intrinsic part of the very nature of data science. For example, a data scientist may work in the following steps&lt;ul&gt;
&lt;li&gt;read raw data from disk and do some cleansing and transformation. Call this pristine data&lt;/li&gt;
&lt;li&gt;repeatedly make a copy of the pristine data, slice and dice it, explore alternatives, backtrack, explore other alternatives. Without a repl, we would need to keep saving the pristine data to disk and reload it when the program start, which makes for a terrible exploratory experience&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The need for speed. More often than not, todays data is &lt;strong&gt;big&lt;/strong&gt; data. We need computation speeds approaching C/C++ or at least java. Certainly not the speed of python&lt;/li&gt;
&lt;li&gt;The need for rich text and graphical output. If you're a data scientist, you usually want to tell a story with the data. You want to write headings, you want boldface, italics, images, graphs and tables to tell your story. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The reason that python is bad for data science today is due to the third point. &lt;strong&gt;Python is very slow&lt;/strong&gt; and not really suitable for data of (say) tens of GBs. Currently the workaround is to use an optimized library such as &lt;code&gt;pandas&lt;/code&gt;. However, pandas is fast only because the core parts are implemented in C (the so called &lt;code&gt;vectorized operations&lt;/code&gt;). Pandas itself has weird quirks which I will cover in a later blog. If you ever need something that is not available in pandas, well good luck writing a C binding for python code.&lt;/p&gt;
&lt;h2&gt;Julia&lt;/h2&gt;
&lt;p&gt;Enter Julia, the latest kid on the block. Sometimes it feels like a supwerpowered mutant language. Some examples&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It is &lt;em&gt;optionally&lt;/em&gt; typed. You can go with either static or dynamic typing&lt;/li&gt;
&lt;li&gt;It compiles to native code thus offering C like performance&lt;/li&gt;
&lt;li&gt;It is purpose built for data science and thus offers a true REPL. (languages like java offer a REPL as an afterthoughts and are not really true REPLs)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;However, in practice, the language is pretty far from mainstream adoption&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The native speed is obtained only under specific conditions. For example, that all variables are statically typed. In general, it is extremely easy to screw up performance by forgetting to declare the types of some variables&lt;/li&gt;
&lt;li&gt;The REPL compilation is mind numbingly slow. It takes several seconds or sometimes minutes to (just in time) compile the code. It leads to a very frustrating experience&lt;/li&gt;
&lt;li&gt;This last point does not really have to with Julia, but rather to do with the need for rich text and graphical output. Currently, the de-facto standard for this rich graphical environment is the Jupyter notebook running on a browser. However, the user experience is far from satisfactory due to the inability to use your favorite IDE and all the tooling that comes along with it, for example, autocomplete, familiar key mappings, debugging tools, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thus data science today is in a sad state. Julia tries to fix it. Its heart is in the right place, but it is unlikely it will ever be as usable as python in the repl, while maintaining the speed of C.&lt;/p&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;Programming languages were designed to solve specific classes of problems. Understanding the motivation and architecture of programming languages allows us to pick one that is well suited for the task at hand. On the flip side, a bad choice can quickly burden the dev team with tech debt. &lt;/p&gt;</content><category term="misc"></category><category term="misc"></category></entry><entry><title>Notes on Postgres WAL and logical replication</title><link href="/notes-on-postgres-wal-and-logical-replication.html" rel="alternate"></link><published>2021-09-20T22:30:00+00:00</published><updated>2021-09-20T22:30:00+00:00</updated><author><name>Sharath Gururaj</name></author><id>tag:None,2021-09-20:/notes-on-postgres-wal-and-logical-replication.html</id><summary type="html">&lt;p&gt;We are trying to implement change data capture (CDC) from several postgres databases and expose it as a stream of inserts/updates/deletes to any consumer. &lt;/p&gt;
&lt;p&gt;A couple of properties of all our tables, which makes the design much easier is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;All tables have an immutable primary key (usually a …&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;We are trying to implement change data capture (CDC) from several postgres databases and expose it as a stream of inserts/updates/deletes to any consumer. &lt;/p&gt;
&lt;p&gt;A couple of properties of all our tables, which makes the design much easier is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;All tables have an immutable primary key (usually a UUID), although sometimes, the primary key may be a composite key. It allows us to "replay" rows over and over again, without worrying about duplicates, etc&lt;/li&gt;
&lt;li&gt;All tables also have audit columns (created_at, updated_at). It allows us to query changes since (say) yesterday and reingest the data using the immutable primary keys&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here are some practical requirements from any such CDC system.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In case the destination crashes, we want to replay the changes from the last X days (assuming WAL logs are maintained)&lt;/li&gt;
&lt;li&gt;In case of master failover to replica, we want to "continue from where the master fell off", or at least, rewind back a couple of hours and replay the messages.&lt;/li&gt;
&lt;li&gt;We want to selectively choose what tables to replicate, and this set of tables might change. (typically, new tables will be added to the captured list)`&lt;/li&gt;
&lt;li&gt;The ability to perform parallel initial snapshot and streaming, and the ability to resume initial snapshot in case of error &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;em&gt;de facto&lt;/em&gt; choice for CDC these days is debezium, which uses logical replication to expose a stream of changes. When practically trying to build such a system, we had a hard time figuring out how all the components fit together. The postgres and debezium docs are very good, but they have big gaps if you want to understand the systems well enough to architect a solution. So in this blog, we will cover the missing pieces that we figured out reading the source code. &lt;/p&gt;
&lt;p&gt;This article is meant to be read along with the available documentation of postgres logical replication and debezium documentation. As such, we will not cover introductory things like what is logical replication, etc. we will go straight to the points which we consider is not clear in the documentation. A really fantastic place to get background information is &lt;a href="https://www.interdb.jp/pg/"&gt;https://www.interdb.jp/pg/&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Some implementation details of the postgres WAL mechanism&lt;/h2&gt;
&lt;p&gt;As soon as queries execute &lt;code&gt;insert/delete/updates&lt;/code&gt;, The generated &lt;code&gt;XLogRecords&lt;/code&gt; are put in a shared memory called the &lt;strong&gt;WAL Buffers&lt;/strong&gt;. There is a &lt;strong&gt;WAL Writer&lt;/strong&gt; process that wakes up regularly and flushes the WAL Buffer to disk. Note that this writing happens even for potentially uncommited transactions. The fact that a transaction is rolled back is handled by simply marking the transaction in the &lt;code&gt;pg_xact&lt;/code&gt; as &lt;code&gt;rolled_back&lt;/code&gt;. There are two invariants that are maintained.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;All &lt;code&gt;XLogRecords&lt;/code&gt; are flushed to disk at some point &lt;strong&gt;before&lt;/strong&gt; the transaction is marked as committed&lt;/li&gt;
&lt;li&gt;When the WAL Writer kicks in, all &lt;code&gt;XLogRecords&lt;/code&gt; &lt;strong&gt;upto a specific LSN&lt;/strong&gt; are written. This means that &lt;strong&gt;&lt;code&gt;XLogRecords&lt;/code&gt; from different transactions can be intermixed freeley&lt;/strong&gt;. For example, the following is a valid sequence of records in the WAL File&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;begin_tx1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;begin_tx2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;tx1_xlogrecord1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;tx2_xlogrecord1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;commit_tx1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;commit_tx2&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Some implementation details of logical replication&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;On the server side, the replication slot primarily holds information about how much LSN the client has read so far.&lt;/li&gt;
&lt;li&gt;On the server side the flow of reading the logs is like this&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;WalSender&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;--&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ReorderBuffer&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;--&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;OutputPlugin&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;example&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;pgoutput&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;Each replication slot has its own WALSender process. &lt;/li&gt;
&lt;li&gt;The output plugin free to do whatever it wants with the decoded &lt;code&gt;XLogRecords&lt;/code&gt;. It may or may not send the changes over on the network to a remote peer. For example, there is a &lt;a href="https://www.postgresql.org/docs/10/logicaldecoding-example.html"&gt;SQL interface&lt;/a&gt; which is a plugin which exposes the functionalities through a few SQL functions. &lt;/li&gt;
&lt;li&gt;Any logical replication plugin must be associated with a replication slot to start doing the magic.&lt;/li&gt;
&lt;li&gt;pgoutput is one such plugin, that streams the changes over the network, with a well defined &lt;a href="https://www.postgresql.org/docs/current/protocol-logical-replication.html"&gt;protocol&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;On the client side, the WALReciever process understands the protocol of pgoutput, and converts the messages to SQL and replays it on the client.&lt;/li&gt;
&lt;li&gt;As with all output plugins, pgoutput also requires a replication slot. However, unlike other plugins, pgoutput requires another object called a &lt;em&gt;publication&lt;/em&gt;. The publication is effectively nothing more than a list of tables that need to be captured. It is read only during the startup of streaming, or when we manually refresh a publication&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now we would like to point out a tricky implementation detail.
- On the server side, we saw that WAL files contain &lt;code&gt;XLogRecords&lt;/code&gt; intermixed records from different transactions. However, when the changes appear on the client side, they are no longer intermixed. For example, suppose the WAL file on server looks like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;begin_tx1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;begin_tx2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;tx1_xlogrecord1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;tx2_xlogrecord1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;commit_tx1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;commit_tx2&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;but the client sees the changes look like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;begin_tx1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;tx1_xlogrecord1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;commit_tx1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;begin_tx2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;tx2_xlogrecord1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;commit_tx2&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This magic is performed by the &lt;code&gt;ReorderBuffer&lt;/code&gt; module pointed out above. Note that this component comes before the output plugins, so all output plugins behave this way. &lt;/p&gt;
&lt;p&gt;By now, you must be wondering that the only way to accomplish is to buffer the &lt;code&gt;XLogRecords&lt;/code&gt; in memory until we encounter the commit record, and then emit all changes without intermix.&lt;/p&gt;
&lt;p&gt;Well you are right. ReorderBuffer does exactly that. The astute observer will note that the amount of transaction record can grow big. Much bigger than available memory. Well, the ReorderBuffer infact has the capability to splill its data structures to disk to accomplish this de-intermix!&lt;/p&gt;
&lt;p&gt;The pseudocode of ReorderBuffer is something like this&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="mf"&gt;1.&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Maintain&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;datastructure&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;recordMap&lt;/span&gt;&lt;span class="p"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Map&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;txid&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;List&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;XLogRecords&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="mf"&gt;2.&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;reading&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;the&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;WAL&lt;/span&gt;
&lt;span class="mf"&gt;3.&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;each&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;XLogRecord&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;rec&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="w"&gt;       &lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;recordMap&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="na"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rec&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="na"&gt;txid&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="na"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rec&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="w"&gt;       &lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;the&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;list&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;is&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;bigger&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;than&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;threshold&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;spill&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;to&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;disk&lt;/span&gt;
&lt;span class="w"&gt;       &lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;rec&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="n"&gt;COMMIT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;then&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;emit&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;all&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;the&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;changes&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;of&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;recordMap&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="na"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rec&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="na"&gt;txid&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;An important consequence of this "de-mixing" is that the LSN of records as seen by the client need not be in increasing order.
However, the following two invariants are still maintained
- LSNs of each transaction is ordered
- LSNs of commit messages are ordered&lt;/p&gt;
&lt;h2&gt;Keeping track of progress of logical replication&lt;/h2&gt;
&lt;p&gt;Periodically, the client sends back heartbeat messages to server, which contain the following three lsns. 
- confirm_flush_lsn
- recieve_lsn
- apply_lsn&lt;/p&gt;
&lt;p&gt;To understand these LSN, consider the client as a database. When it recieves a message, it performs the following steps
- recieve the lsn
- apply it to tables
- fsync and flush the changes&lt;/p&gt;
&lt;p&gt;So each lsn corresponds to these steps. Usually, &lt;code&gt;recieve_lsn&amp;gt;apply_lsn&amp;gt;flush_lsn&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Of course, a client may not actually use three different steps. The most important of these is &lt;code&gt;flush_lsn&lt;/code&gt;. It tells the server that lsns before this will no longer be required by the client and free to reclaim the space in WAL&lt;/p&gt;
&lt;h2&gt;On server restart, from where does the server restart the WAL decoding?&lt;/h2&gt;
&lt;p&gt;The server keeps track of all three progress lsns. In particular the &lt;code&gt;flush_lsn&lt;/code&gt;. So logically, one might think that on restart, this is the point from where the server will play back the WAL. However, the server persists the &lt;code&gt;flush_lsn&lt;/code&gt; only at checkpoint, so it is entirely possible that the client may recieve duplicate entries on restart. It is upto the client to skip duplicates. Furthermore, one can actually specify the restart LSN during startup.&lt;/p&gt;
&lt;p&gt;There is in fact another LSN called &lt;code&gt;restart_lsn&lt;/code&gt; that is tracked by the server. We are not able to figure out the difference between &lt;code&gt;restart_lsn&lt;/code&gt; and &lt;code&gt;flush_lsn&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;Some notes for architects&lt;/h2&gt;
&lt;p&gt;Q: How far can I go back and restart the streaming?&lt;br/&gt;
A: By cleverly controlling flush_lsn, you can control the amount of WAL retained on the server.&lt;/p&gt;
&lt;p&gt;Q: How do we make sure server does not crash due to WAL locking up disk space due to inactive replication client&lt;br/&gt;
A: You can play with some postgres parameters, notably &lt;code&gt;wal_keep_size&lt;/code&gt; and &lt;code&gt;max_slot_wal_keep_size&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Q: How do we get resumable and parallel initial snapshots?&lt;br/&gt;
A: refers to these links. &lt;a href="https://github.com/debezium/debezium-design-documents/blob/main/DDD-3.md"&gt;DDD-3&lt;/a&gt; and &lt;a href="https://arxiv.org/pdf/2010.12597v1.pdf"&gt;DbLog&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Q: If the master fails-over to a replica, the LSNs will go out of sync. Do we need to resetup the entire snapshot?&lt;br/&gt;
A: Here's the idea:
- create a replication slot on the new primary (previously standby)
- issue a query like so &lt;code&gt;select * from mytable where updated_at &amp;gt; now()-2hrs&lt;/code&gt;. Once it's done, start the streaming replication.
Assuming your primary keys are idempotent, you should be back in business&lt;/p&gt;
&lt;p&gt;Q: How can we add or remove from the list of captured tables?&lt;br/&gt;
A: Since debezium reads pgoutput protocol, just alter the publication and restart debezium &lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Logical decoding is a very powerful tool in the data engineering toolkit. It opens up a host of possibilities. we hope this article fills in the gap left in official documentation and enables architects to design effective CDC systems.&lt;/p&gt;</content><category term="misc"></category><category term="misc"></category></entry><entry><title>Cookbook</title><link href="/cookbook.html" rel="alternate"></link><published>2020-08-31T12:22:00+00:00</published><updated>2020-08-31T12:22:00+00:00</updated><author><name>Sharath Gururaj</name></author><id>tag:None,2020-08-31:/cookbook.html</id><summary type="html">&lt;p&gt;This article captures cookbooks or recipes that I don't use frequently enough to remember, but still use it enough to be painful to google from scratch every time I use it. Its a bunch of totally unrelated stuff that is too short to put as a blog article on its …&lt;/p&gt;</summary><content type="html">&lt;p&gt;This article captures cookbooks or recipes that I don't use frequently enough to remember, but still use it enough to be painful to google from scratch every time I use it. Its a bunch of totally unrelated stuff that is too short to put as a blog article on its own. Hopefully, you'll find the table of contexts helpful to navigate.
(the links are not working yet :( )&lt;/p&gt;
&lt;h1&gt;&lt;a name="table-of-contents" href="#table-of-contents"&gt;Table of contents&lt;/a&gt;&lt;/h1&gt;
&lt;!-- toc --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#table-of-contents"&gt;Table of contents&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#julia-arrays"&gt;Julia Arrays&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#anaconda-dont-start-at-shell"&gt;Anaconda dont start at shell&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#how-to-mount-samba-folder-in-ubuntu"&gt;How to mount samba folder in ubuntu&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#how-to-use-du-to-search-for-hidden-folders"&gt;How to use du to search for hidden folders&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#sublime-text-keyboard-shortcuts"&gt;Sublime text keyboard shortcuts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#making-nomachine-nx-work-on-amazon-aws-ec2"&gt;Making Nomachine nx work on amazon aws ec2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#remote-desktop-to-raspberry-pi"&gt;Remote desktop to raspberry pi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#echo-server-with-netcat"&gt;Echo server with netcat &lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#mounting-a-disk-on-gcp"&gt;Mounting a disk on GCP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#describe-type-of-command"&gt;Describe type of command&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#linux-networking"&gt;Linux Networking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#postgres"&gt;Postgres&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#intellij-shortcuts"&gt;Intellij Shortcuts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#bash-shortcuts"&gt;Bash shortcuts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#how-to-setup-a-new-linux-machine"&gt;How to setup a new linux machine&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#python-regex-recipes"&gt;Python regex recipes &lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#vim-one-liners-and-shortcuts"&gt;Vim one liners and shortcuts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#cscope-for-linux"&gt;Cscope for linux &lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#cscope-for-ceph"&gt;Cscope for ceph&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#building-linux"&gt;Building linux&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#using-ftrace-to-trace-linux-functions"&gt;Using Ftrace to trace linux functions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#how-to-build-linux-on-one-machine-and-deploy-on-another"&gt;How to build linux on one machine and deploy on another&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#jemalloc"&gt;JeMalloc &lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#objdump"&gt;Objdump&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#installing-latest-version-of-cmake"&gt;Installing latest version of cmake&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#getting-honest-profiler-to-work"&gt;Getting honest profiler to work&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#gcc-important-options"&gt;GCC important options&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#eli-bendersky-static-linking-summary"&gt;Eli bendersky static linking summary&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#eli-bendersky-load-time-linking-summary"&gt;Eli bendersky load time linking summary&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#eli-bendersky-x32-pic-linking-summary"&gt;Eli bendersky x32 PIC linking summary&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#linux-interrupt-handling"&gt;Linux Interrupt Handling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#hdfs-proxy-user-setting"&gt;HDFS proxy user setting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#http-proxy-with-squid"&gt;Http proxy with squid&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#kafka-metrics"&gt;kafka metrics&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- tocstop --&gt;

&lt;h1&gt;&lt;a name="julia-arrays" href="#julia-arrays"&gt;Julia Arrays&lt;/a&gt;&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;tabs or spaces: concat to the right&lt;/li&gt;
&lt;li&gt;semicolon or newline: concat to the bottom &lt;/li&gt;
&lt;li&gt;one dimensional arrays are considered as column vectors for concatenation purposes&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a name="anaconda-dont-start-at-shell" href="#anaconda-dont-start-at-shell"&gt;Anaconda dont start at shell&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;If you'd prefer that conda's base environment not be activated on startup, &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;conda&lt;span class="w"&gt; &lt;/span&gt;config&lt;span class="w"&gt; &lt;/span&gt;--set&lt;span class="w"&gt; &lt;/span&gt;auto_activate_base&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;false&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h1&gt;&lt;a name="how-to-mount-samba-folder-in-ubuntu" href="#how-to-mount-samba-folder-in-ubuntu"&gt;How to mount samba folder in ubuntu&lt;/a&gt;&lt;/h1&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;sudo&lt;span class="w"&gt; &lt;/span&gt;mount&lt;span class="w"&gt; &lt;/span&gt;-t&lt;span class="w"&gt; &lt;/span&gt;cifs&lt;span class="w"&gt; &lt;/span&gt;-o&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;user&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;sharath&lt;span class="w"&gt; &lt;/span&gt;//192.168.29.28/HOMEPI&lt;span class="w"&gt; &lt;/span&gt;/mnt/pi
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h1&gt;&lt;a name="how-to-use-du-to-search-for-hidden-folders" href="#how-to-use-du-to-search-for-hidden-folders"&gt;How to use du to search for hidden folders&lt;/a&gt;&lt;/h1&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;du&lt;span class="w"&gt; &lt;/span&gt;-schx&lt;span class="w"&gt; &lt;/span&gt;.&lt;span class="o"&gt;[&lt;/span&gt;!.&lt;span class="o"&gt;]&lt;/span&gt;*&lt;span class="w"&gt; &lt;/span&gt;*
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;To exclude other mount points use &lt;code&gt;--exclude&lt;/code&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a name="sublime-text-keyboard-shortcuts" href="#sublime-text-keyboard-shortcuts"&gt;Sublime text keyboard shortcuts&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Open any file &lt;code&gt;ctrl-p&lt;/code&gt;
Open any command &lt;code&gt;ctrl-shift-p&lt;/code&gt;
Close tab: mac &lt;code&gt;cmd+w&lt;/code&gt;
Linux &lt;code&gt;ctrl-shift-w&lt;/code&gt;
Jump back &lt;code&gt;alt -&lt;/code&gt; 
forward &lt;code&gt;alt +&lt;/code&gt; &lt;/p&gt;
&lt;h1&gt;&lt;a name="making-nomachine-nx-work-on-amazon-aws-ec2" href="#making-nomachine-nx-work-on-amazon-aws-ec2"&gt;Making Nomachine nx work on amazon aws ec2&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;First, download the nx package from nomachine and &lt;code&gt;dpkg -i&lt;/code&gt; the package
The software is installed in &lt;code&gt;/usr/NX&lt;/code&gt;
We have to first disable password login and only use certificate login. To do this, edit the file &lt;code&gt;vim /usr/NX/etc/server.config&lt;/code&gt; and add this line. After this, restart the nx server &lt;code&gt;/usr/NX/bin/nxserver --restart&lt;/code&gt;
Verify that password login does not work
For resolution, the key idea is that there should be no x server running already on the machine. If there is no x server, then nx will create its own, and by default try to match the client resolution, which is what we want. Unfortunately, when we install gnome desktop, it automatically changes the systemd runlevel to graphical.target which means systemd will spawn gdm and an xserver /usr/lib/xorg/Xorg (hope you dont get into wayland and shit). So we have to change the default systemd target to shell mode, which can be done by &lt;code&gt;sudo systemctl set-default multi-user.target&lt;/code&gt;* 
And thats it, nx should automatically try to match client resolution if client is running in full screen mode!&lt;/p&gt;
&lt;p&gt;Sometimes, you will see a black screen when you login, to solve this&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;sudo&lt;span class="w"&gt; &lt;/span&gt;service&lt;span class="w"&gt; &lt;/span&gt;gdm&lt;span class="w"&gt; &lt;/span&gt;stop
/usr/NX/bin/nxserver&lt;span class="w"&gt; &lt;/span&gt;--restart
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h1&gt;&lt;a name="remote-desktop-to-raspberry-pi" href="#remote-desktop-to-raspberry-pi"&gt;Remote desktop to raspberry pi&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;We will use real vnc. From terminal, ssh to raspberry pi. On the pi run
&lt;code&gt;vncserver -geometry 1920x1080&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;From the client, run vncviewer from real vnc and login. You have to do this every time you want to login&lt;/p&gt;
&lt;h1&gt;&lt;a name="echo-server-with-netcat" href="#echo-server-with-netcat"&gt;Echo server with netcat &lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Server
&lt;code&gt;ncat -e /bin/cat -k  -l 8888 &amp;lt;ip&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Client 
&lt;code&gt;telnet ip 8888&lt;/code&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a name="mounting-a-disk-on-gcp" href="#mounting-a-disk-on-gcp"&gt;Mounting a disk on GCP&lt;/a&gt;&lt;/h1&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;sudo&lt;span class="w"&gt; &lt;/span&gt;lsblk
sudo&lt;span class="w"&gt; &lt;/span&gt;mkdir&lt;span class="w"&gt; &lt;/span&gt;-p&lt;span class="w"&gt; &lt;/span&gt;/mnt/disks/sdb
sudo&lt;span class="w"&gt; &lt;/span&gt;cp&lt;span class="w"&gt; &lt;/span&gt;/etc/fstab&lt;span class="w"&gt; &lt;/span&gt;/etc/fstab.backup
sudo&lt;span class="w"&gt; &lt;/span&gt;blkid&lt;span class="w"&gt; &lt;/span&gt;/dev/sdb
In&lt;span class="w"&gt; &lt;/span&gt;/etc/fstb
&lt;span class="nv"&gt;UUID&lt;/span&gt;&lt;span class="o"&gt;=[&lt;/span&gt;UUID_VALUE&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;/mnt/disks/&lt;span class="o"&gt;[&lt;/span&gt;MNT_DIR&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;ext4&lt;span class="w"&gt; &lt;/span&gt;discard,defaults,nofail&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;
Sudo&lt;span class="w"&gt; &lt;/span&gt;mount&lt;span class="w"&gt; &lt;/span&gt;-a&lt;span class="w"&gt; &lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h1&gt;&lt;a name="describe-type-of-command" href="#describe-type-of-command"&gt;Describe type of command&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;&lt;code&gt;type ls&lt;/code&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a name="linux-networking" href="#linux-networking"&gt;Linux Networking&lt;/a&gt;&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Netfilter&lt;/strong&gt;: linux component which has various hooks for network packet manipulation
The netfilter hooks are exposed through various  userspace programs: notably &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Iptables&lt;/strong&gt; : which is the userspace interface to linux firewall, (firewall here simply means configuring netfilter according to some rules), nat mangling etc &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Subnetting/CIDR&lt;/strong&gt; : CIDR splits 32 bit ipv4 addresses into two parts: left part is network part. Right part is host part. This act is called subnetting. &lt;code&gt;0.0.0.0/24&lt;/code&gt; Here 24 means, the network part (left part) is 24 bits. The host part (right part is 32-24 = 8) bits. Usually in large companies different networks are indeed different networks. I.e., we need routing between two subnets. With a single (sub)network, there is no need for routing (works like lan)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Network interfaces&lt;/strong&gt;: on the linux level, they are network devices, with a device driver. They get a packet trhough hard_start_xmit() and they can do whatever they want with it. See this for a good example&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bridge&lt;/strong&gt;: when referring to a hardware device it is a connector at L2. i.e., it learns mac addresses and forwards packets from one network to another switch is also essentially the same thing&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Linux software bridge device&lt;/strong&gt;:  is a software network_interface which acts like a bridge between two other network interfaces&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a name="postgres" href="#postgres"&gt;Postgres&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;To create a data directory, first &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;mkdir&lt;span class="w"&gt; &lt;/span&gt;-p&lt;span class="w"&gt; &lt;/span&gt;/path/to/data
chown&lt;span class="w"&gt; &lt;/span&gt;postgres&lt;span class="w"&gt;  &lt;/span&gt;/path/to/data
Sudo&lt;span class="w"&gt; &lt;/span&gt;-u&lt;span class="w"&gt; &lt;/span&gt;postgres&lt;span class="w"&gt; &lt;/span&gt;/usr/lib/postgresql/11/bin/Initdb&lt;span class="w"&gt; &lt;/span&gt;-D&lt;span class="w"&gt; &lt;/span&gt;/path/to/data
vim&lt;span class="w"&gt; &lt;/span&gt;/etc/postgresql/11/main/postgresql.conf&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;#and modify the data_dir&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;To make postgres listen to remote connections in the same file:
&lt;code&gt;listen_addresses = '*'&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;vim /etc/postgresql/11/main/pg_hba.conf&lt;/code&gt;
Add this line (probably give stronger restrictions)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;host    all             all             0.0.0.0/0            md5
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Restart postgres. There are several ways. One of these should work:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;Sudo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;service&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;postgresql&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;restart&lt;/span&gt;
&lt;span class="n"&gt;Or&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;pg_ctlcluster&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;
&lt;span class="n"&gt;Or&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
&lt;span class="n"&gt;pg_ctl&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;usr&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;local&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;var&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;postgres&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;
&lt;span class="n"&gt;Or&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;usr&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;lib&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;postgresql&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;bin&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;pg_ctl&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;etc&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;postgresql&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;logfile&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;
&lt;span class="n"&gt;Or&lt;/span&gt;
&lt;span class="w"&gt;   &lt;/span&gt;&lt;span class="n"&gt;sudo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;systemctl&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;postgresql&lt;/span&gt;&lt;span class="mi"&gt;@10&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;main&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Create users by first logging in &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;sudo&lt;span class="w"&gt; &lt;/span&gt;-u&lt;span class="w"&gt; &lt;/span&gt;postgres&lt;span class="w"&gt; &lt;/span&gt;psql
create&lt;span class="w"&gt; &lt;/span&gt;user&lt;span class="w"&gt; &lt;/span&gt;sharath&lt;span class="w"&gt; &lt;/span&gt;with&lt;span class="w"&gt; &lt;/span&gt;encrypted&lt;span class="w"&gt; &lt;/span&gt;password&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;foo&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
ALTER&lt;span class="w"&gt; &lt;/span&gt;USER&lt;span class="w"&gt; &lt;/span&gt;sharath&lt;span class="w"&gt; &lt;/span&gt;WITH&lt;span class="w"&gt; &lt;/span&gt;SUPERUSER&lt;span class="p"&gt;;&lt;/span&gt;
create&lt;span class="w"&gt; &lt;/span&gt;database&lt;span class="w"&gt; &lt;/span&gt;sharath&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="c1"&gt;#To enable the logs in /etc/postgresql/11/main/postgresql.conf&lt;/span&gt;
&lt;span class="nv"&gt;log_destination&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;csvlog&amp;#39;&lt;/span&gt;
&lt;span class="nv"&gt;logging_collector&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;on
&lt;span class="nv"&gt;log_rotation_age&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;0d
&lt;span class="nv"&gt;log_statement&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;all&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;To view the logs
&lt;code&gt;sudo grep SQLEditor /var/lib/postgresql/12/main/log/* |grep -v pg_catalog | grep -v SHOW | grep -v current_schema&lt;/code&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a name="intellij-shortcuts" href="#intellij-shortcuts"&gt;Intellij Shortcuts&lt;/a&gt;&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Ctrl+shift+enter to complete statement after code completion. Its pretty magical. &lt;/li&gt;
&lt;li&gt;Alt+j to select all instances&lt;/li&gt;
&lt;li&gt;Tab after ctrl-space overwrites rather than insert&lt;/li&gt;
&lt;li&gt;Ctrl+alt-l to reformat whole file or selections&lt;/li&gt;
&lt;li&gt;Ctrl+shift+i to see the definition (code) for the method&lt;/li&gt;
&lt;li&gt;F2 to go to next highlighted error&lt;/li&gt;
&lt;li&gt;F4 go to definition&lt;/li&gt;
&lt;li&gt;Ctrl-f12 to see the file structure&lt;/li&gt;
&lt;li&gt;Ctrl+shift+numpad- collapse all&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a name="bash-shortcuts" href="#bash-shortcuts"&gt;Bash shortcuts&lt;/a&gt;&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Alt-B back one word&lt;/li&gt;
&lt;li&gt;Alt-f forward one word&lt;/li&gt;
&lt;li&gt;Ctrl-w delete back one word&lt;/li&gt;
&lt;li&gt;alt-D delete till end of word&lt;/li&gt;
&lt;li&gt;Ctrl-U delete to start of line&lt;/li&gt;
&lt;li&gt;Ctrl-k delete to end of line&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a name="how-to-setup-a-new-linux-machine" href="#how-to-setup-a-new-linux-machine"&gt;How to setup a new linux machine&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;First, login as root. Here nm&amp;gt; means new machine and local&amp;gt; means laptop&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;nm&amp;gt;&lt;span class="w"&gt; &lt;/span&gt;
adduser&lt;span class="w"&gt; &lt;/span&gt;-u&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;1001&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;sharath&lt;span class="p"&gt;;&lt;/span&gt;
usermod&lt;span class="w"&gt; &lt;/span&gt;-aG&lt;span class="w"&gt; &lt;/span&gt;sudo&lt;span class="w"&gt; &lt;/span&gt;sharath
su&lt;span class="w"&gt; &lt;/span&gt;-&lt;span class="w"&gt; &lt;/span&gt;sharath
ssh-keygen&lt;span class="w"&gt; &lt;/span&gt;-t&lt;span class="w"&gt; &lt;/span&gt;rsa&lt;span class="w"&gt; &lt;/span&gt;-N&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-f&lt;span class="w"&gt; &lt;/span&gt;~/.ssh/id_rsa
&amp;lt;create&lt;span class="w"&gt; &lt;/span&gt;a&lt;span class="w"&gt; &lt;/span&gt;new&lt;span class="w"&gt; &lt;/span&gt;key&amp;gt;
&amp;lt;copy&lt;span class="w"&gt; &lt;/span&gt;your&lt;span class="w"&gt; &lt;/span&gt;localhost&lt;span class="w"&gt; &lt;/span&gt;id_rsa.pub&lt;span class="w"&gt; &lt;/span&gt;into&lt;span class="w"&gt; &lt;/span&gt;clipboard&amp;gt;
vim&lt;span class="w"&gt; &lt;/span&gt;/home/sharath/.ssh/authorized_keys&lt;span class="w"&gt; &lt;/span&gt;
&amp;lt;paste&lt;span class="w"&gt; &lt;/span&gt;your&lt;span class="w"&gt; &lt;/span&gt;id_rsa.pub&lt;span class="w"&gt; &lt;/span&gt;and&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;exit&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;vim&amp;gt;
chmod&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;644&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;/home/sharath/.ssh/authorized_keys
&lt;span class="nb"&gt;echo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;sharath ALL=(ALL) NOPASSWD: ALL&amp;#39;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;sudo&lt;span class="w"&gt; &lt;/span&gt;tee&lt;span class="w"&gt; &lt;/span&gt;/etc/sudoers.d/sharath
sudo&lt;span class="w"&gt; &lt;/span&gt;chmod&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;0440&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;/etc/sudoers.d/sharath
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;IMPROVED (scriptable)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;First,&lt;span class="w"&gt; &lt;/span&gt;copy&lt;span class="w"&gt; &lt;/span&gt;your&lt;span class="w"&gt; &lt;/span&gt;public&lt;span class="w"&gt; &lt;/span&gt;key&lt;span class="w"&gt; &lt;/span&gt;to&lt;span class="w"&gt; &lt;/span&gt;tmp&lt;span class="w"&gt; &lt;/span&gt;on&lt;span class="w"&gt; &lt;/span&gt;nm,&lt;span class="w"&gt; &lt;/span&gt;like&lt;span class="w"&gt; &lt;/span&gt;so
scp&lt;span class="w"&gt; &lt;/span&gt;~/.ssh/id_rsa.pub&lt;span class="w"&gt; &lt;/span&gt;root@&amp;lt;new_ip&amp;gt;:/tmp/ak&lt;span class="w"&gt; &lt;/span&gt;

Login&lt;span class="w"&gt; &lt;/span&gt;to&lt;span class="w"&gt; &lt;/span&gt;the&lt;span class="w"&gt; &lt;/span&gt;new&lt;span class="w"&gt; &lt;/span&gt;box&lt;span class="w"&gt; &lt;/span&gt;as&lt;span class="w"&gt; &lt;/span&gt;root&lt;span class="w"&gt; &lt;/span&gt;and&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;do&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;the&lt;span class="w"&gt; &lt;/span&gt;following
adduser&lt;span class="w"&gt; &lt;/span&gt;--disabled-password&lt;span class="w"&gt; &lt;/span&gt;--gecos&lt;span class="w"&gt; &lt;/span&gt;‘’&lt;span class="w"&gt; &lt;/span&gt;sharath
usermod&lt;span class="w"&gt; &lt;/span&gt;-aG&lt;span class="w"&gt; &lt;/span&gt;sudo&lt;span class="w"&gt; &lt;/span&gt;sharath
su&lt;span class="w"&gt; &lt;/span&gt;-&lt;span class="w"&gt; &lt;/span&gt;sharath
ssh-keygen&lt;span class="w"&gt; &lt;/span&gt;-t&lt;span class="w"&gt; &lt;/span&gt;rsa&lt;span class="w"&gt; &lt;/span&gt;-N&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-f&lt;span class="w"&gt; &lt;/span&gt;~/.ssh/id_rsa
&lt;span class="nb"&gt;exit&lt;/span&gt;
cp&lt;span class="w"&gt; &lt;/span&gt;/tmp/ak&lt;span class="w"&gt; &lt;/span&gt;/home/sharath/.ssh/authorized_keys
chmod&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;644&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;/home/sharath/.ssh/authorized_keys
&lt;span class="nb"&gt;echo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;sharath ALL=(ALL) NOPASSWD: ALL&amp;#39;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;sudo&lt;span class="w"&gt; &lt;/span&gt;tee&lt;span class="w"&gt; &lt;/span&gt;/etc/sudoers.d/sharath
sudo&lt;span class="w"&gt; &lt;/span&gt;chmod&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;0440&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;/etc/sudoers.d/sharath
rm&lt;span class="w"&gt; &lt;/span&gt;/tmp/ak
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Bob should be your uncle&lt;/p&gt;
&lt;h1&gt;&lt;a name="python-regex-recipes" href="#python-regex-recipes"&gt;Python regex recipes &lt;/a&gt;&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;\s whitespace&lt;/li&gt;
&lt;li&gt;\S non whitespace&lt;/li&gt;
&lt;li&gt;\d only digits&lt;/li&gt;
&lt;li&gt;\D non digits&lt;/li&gt;
&lt;li&gt;\w alphanumeric [a-zA-Z0-9_]&lt;/li&gt;
&lt;li&gt;\W non-alphanumeric&lt;/li&gt;
&lt;li&gt;\d{1,3}.\d{1,3}.\d{1,3}.\d{1,3} ip regex&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;groups enclose in (), numbered from x.group(1)
named groups like this &lt;code&gt;(?P&amp;lt;name) access with x.group("name")&lt;/code&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;re&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;compile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;regexStr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;finditer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;group&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;group&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;re&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;compile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;r&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;(blue|red)&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sub&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;group&lt;/span&gt;&lt;span class="p"&gt;())),&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;blue socks and red shoes&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;prints &lt;code&gt;4 socks and 3 shoes&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;validate a regex on https://regex101.com/&lt;/p&gt;
&lt;h1&gt;&lt;a name="vim-one-liners-and-shortcuts" href="#vim-one-liners-and-shortcuts"&gt;Vim one liners and shortcuts&lt;/a&gt;&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;gd will go to local definition&lt;/li&gt;
&lt;li&gt;gD will go to global definition &lt;/li&gt;
&lt;li&gt;,c&lt;space&gt; toggle comment&lt;/li&gt;
&lt;li&gt;&lt;ctrl&gt;]  goes to a tag&lt;/li&gt;
&lt;li&gt;&lt;ctrl&gt;o (“old” comes back from a jump)&lt;/li&gt;
&lt;li&gt;&lt;ctrl&gt; i (opposite of &lt;ctrl&gt;o&lt;/li&gt;
&lt;li&gt;Split window ctrl-w v or o&lt;/li&gt;
&lt;li&gt;Scroll up/down, keeping your cursor in its row&lt;/li&gt;
&lt;li&gt;One line&lt;/li&gt;
&lt;li&gt;Ctrl+Y → Move viewport down&lt;/li&gt;
&lt;li&gt;Ctrl+E → Move viewport up (Extra lines)&lt;/li&gt;
&lt;li&gt;Column select &lt;ctrl&gt;v &lt;/li&gt;
&lt;li&gt;Go to beginning of function (go to { in first column: needs coding convention) [[ &lt;/li&gt;
&lt;li&gt;End of function ]]&lt;/li&gt;
&lt;li&gt;Beginning of code block: [{ this one should work better with messed up coding convention&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a name="cscope-for-linux" href="#cscope-for-linux"&gt;Cscope for linux &lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;To apply debian patches use &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nb"&gt;export&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;LNX&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/home/sharath/os/linux/linux-5.4.0
quilt&lt;span class="w"&gt; &lt;/span&gt;push&lt;span class="w"&gt; &lt;/span&gt;-a&lt;span class="w"&gt; &lt;/span&gt;
find&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nv"&gt;$LNX&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;-path&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$LNX&lt;/span&gt;&lt;span class="s2"&gt;/arch/*&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;!&lt;span class="w"&gt; &lt;/span&gt;-path&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$LNX&lt;/span&gt;&lt;span class="s2"&gt;/arch/x86*&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-prune&lt;span class="w"&gt; &lt;/span&gt;-o&lt;span class="w"&gt;  &lt;/span&gt;-path&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$LNX&lt;/span&gt;&lt;span class="s2"&gt;/include/asm-*&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;!&lt;span class="w"&gt; &lt;/span&gt;-path&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$LNX&lt;/span&gt;&lt;span class="s2"&gt;/include/asm-i386*&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-prune&lt;span class="w"&gt; &lt;/span&gt;-o&lt;span class="w"&gt;  &lt;/span&gt;-path&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$LNX&lt;/span&gt;&lt;span class="s2"&gt;/tmp*&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-prune&lt;span class="w"&gt;  &lt;/span&gt;-path&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$LNX&lt;/span&gt;&lt;span class="s2"&gt;/Documentation*&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-prune&lt;span class="w"&gt; &lt;/span&gt;-o&lt;span class="w"&gt;  &lt;/span&gt;-path&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$LNX&lt;/span&gt;&lt;span class="s2"&gt;/scripts*&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-prune&lt;span class="w"&gt; &lt;/span&gt;-o&lt;span class="w"&gt;    &lt;/span&gt;-path&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$LNX&lt;/span&gt;&lt;span class="s2"&gt;/drivers*&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-prune&lt;span class="w"&gt; &lt;/span&gt;-o&lt;span class="w"&gt;   &lt;/span&gt;-path&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$LNX&lt;/span&gt;&lt;span class="s2"&gt;/.pc/*&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-prune&lt;span class="w"&gt; &lt;/span&gt;-o&lt;span class="w"&gt;  &lt;/span&gt;-path&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$LNX&lt;/span&gt;&lt;span class="s2"&gt;/debian/*&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-prune&lt;span class="w"&gt; &lt;/span&gt;-o&lt;span class="w"&gt;   &lt;/span&gt;-path&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$LNX&lt;/span&gt;&lt;span class="s2"&gt;/sound/*&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-prune&lt;span class="w"&gt; &lt;/span&gt;-o&lt;span class="w"&gt;    &lt;/span&gt;-name&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;*.[chxsS]&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-print&lt;span class="w"&gt; &lt;/span&gt;&amp;gt;&lt;span class="w"&gt; &lt;/span&gt;kernel.cscope

cscope&lt;span class="w"&gt; &lt;/span&gt;-q&lt;span class="w"&gt; &lt;/span&gt;-R&lt;span class="w"&gt; &lt;/span&gt;-b&lt;span class="w"&gt; &lt;/span&gt;-i&lt;span class="w"&gt; &lt;/span&gt;cscope.files
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In vim&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;:cs f g &amp;lt;foo&amp;gt; goto definition of foo
:cs f s &amp;lt;foo&amp;gt; find this symbol
:cs f t &amp;lt;foo&amp;gt; find this string
&amp;lt;ctrl&amp;gt;\ s on a word, find this symbol and so on
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h1&gt;&lt;a name="cscope-for-ceph" href="#cscope-for-ceph"&gt;Cscope for ceph&lt;/a&gt;&lt;/h1&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;find&lt;span class="w"&gt; &lt;/span&gt;/mnt/disks/sdb/ceph-pristine&lt;span class="w"&gt; &lt;/span&gt;-type&lt;span class="w"&gt; &lt;/span&gt;f&lt;span class="w"&gt; &lt;/span&gt;-and&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="se"&gt;\(&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-name&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;*.c&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-o&lt;span class="w"&gt; &lt;/span&gt;-name&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;*.h&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-o&lt;span class="w"&gt; &lt;/span&gt;-name&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;*.cc&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-o&lt;span class="w"&gt; &lt;/span&gt;-name&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;*.cpp&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-o&lt;span class="w"&gt; &lt;/span&gt;-name&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;*.hh&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="se"&gt;\)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&amp;gt;&lt;span class="w"&gt; &lt;/span&gt;zoo.cscope
cscope&lt;span class="w"&gt; &lt;/span&gt;-q&lt;span class="w"&gt; &lt;/span&gt;-R&lt;span class="w"&gt; &lt;/span&gt;-b&lt;span class="w"&gt; &lt;/span&gt;-i&lt;span class="w"&gt; &lt;/span&gt;zoo.cscope&lt;span class="w"&gt; &lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h1&gt;&lt;a name="building-linux" href="#building-linux"&gt;Building linux&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;You can get the linux source from 
&lt;code&gt;apt-get source linux-image-unsigned-$(uname -r)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;You can get the config file from 
&lt;code&gt;cp /boot/config-5.4.0-26-generic .config&lt;/code&gt;
To install dependencies&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;sudo&lt;span class="w"&gt; &lt;/span&gt;apt-get&lt;span class="w"&gt; &lt;/span&gt;install&lt;span class="w"&gt; &lt;/span&gt;libncurses-dev&lt;span class="w"&gt; &lt;/span&gt;flex&lt;span class="w"&gt; &lt;/span&gt;bison&lt;span class="w"&gt; &lt;/span&gt;openssl&lt;span class="w"&gt; &lt;/span&gt;libssl-dev&lt;span class="w"&gt; &lt;/span&gt;dkms&lt;span class="w"&gt; &lt;/span&gt;libelf-dev&lt;span class="w"&gt; &lt;/span&gt;libudev-dev&lt;span class="w"&gt; &lt;/span&gt;libpci-dev&lt;span class="w"&gt; &lt;/span&gt;libiberty-dev&lt;span class="w"&gt; &lt;/span&gt;autoconf
sudo&lt;span class="w"&gt; &lt;/span&gt;apt-get&lt;span class="w"&gt; &lt;/span&gt;build-dep&lt;span class="w"&gt; &lt;/span&gt;linux&lt;span class="w"&gt; &lt;/span&gt;linux-image-&lt;span class="k"&gt;$(&lt;/span&gt;uname&lt;span class="w"&gt; &lt;/span&gt;-r&lt;span class="k"&gt;)&lt;/span&gt;

make&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;ARCH&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;x86&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;EXTRAVERSION&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-SS&lt;span class="w"&gt; &lt;/span&gt;-j14&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;make&lt;span class="w"&gt; &lt;/span&gt;-j14&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;ARCH&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;x86&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;EXTRAVERSION&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-SS&lt;span class="w"&gt; &lt;/span&gt;install&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;make&lt;span class="w"&gt; &lt;/span&gt;-j14&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;ARCH&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;x86&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;EXTRAVERSION&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-SS&lt;span class="w"&gt; &lt;/span&gt;modules_install&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;------------------------- DONE --------------------------------&amp;quot;&lt;/span&gt;
rm&lt;span class="w"&gt; &lt;/span&gt;/boot/initrd.img-3.16.43-SS
update-initramfs&lt;span class="w"&gt; &lt;/span&gt;-c&lt;span class="w"&gt; &lt;/span&gt;-k&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;.16.43-SS
update-grub
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h1&gt;&lt;a name="using-ftrace-to-trace-linux-functions" href="#using-ftrace-to-trace-linux-functions"&gt;Using Ftrace to trace linux functions&lt;/a&gt;&lt;/h1&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nb"&gt;echo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;sudo&lt;span class="w"&gt; &lt;/span&gt;tee&lt;span class="w"&gt;  &lt;/span&gt;/sys/kernel/debug/tracing/tracing_on
And&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;then&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;use&lt;span class="w"&gt; &lt;/span&gt;brendan&lt;span class="w"&gt; &lt;/span&gt;greggs&lt;span class="w"&gt; &lt;/span&gt;perf-tools
sudo&lt;span class="w"&gt; &lt;/span&gt;./funcgraph&lt;span class="w"&gt; &lt;/span&gt;-D&lt;span class="w"&gt;  &lt;/span&gt;ext4_readpages&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;sudo&lt;span class="w"&gt; &lt;/span&gt;tee&lt;span class="w"&gt; &lt;/span&gt;/mnt/tmpfs/write
sudo&lt;span class="w"&gt; &lt;/span&gt;./funcgraph&lt;span class="w"&gt; &lt;/span&gt;-Dp&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;51985&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;ext4_readpages&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;sudo&lt;span class="w"&gt; &lt;/span&gt;tee&lt;span class="w"&gt; &lt;/span&gt;/mnt/tmpfs/write
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h1&gt;&lt;a name="how-to-build-linux-on-one-machine-and-deploy-on-another" href="#how-to-build-linux-on-one-machine-and-deploy-on-another"&gt;How to build linux on one machine and deploy on another&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Use “building linux” to build linux on one machine A. Suppose you want to install it on machine B
On machine B&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;Mkdir&lt;span class="w"&gt; &lt;/span&gt;-p&lt;span class="w"&gt; &lt;/span&gt;~/kernel/boot
Mkdir&lt;span class="w"&gt; &lt;/span&gt;-p&lt;span class="w"&gt; &lt;/span&gt;~/kernel/modules
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;On machine A&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;tar&lt;span class="w"&gt; &lt;/span&gt;-cvzf&lt;span class="w"&gt; &lt;/span&gt;~/modules&lt;span class="w"&gt; &lt;/span&gt;/lib/modules/3.16.43-SS
scp&lt;span class="w"&gt; &lt;/span&gt;-r&lt;span class="w"&gt; &lt;/span&gt;*SS*&lt;span class="w"&gt; &lt;/span&gt;&amp;lt;B&amp;gt;:~/kernel/boot
scp&lt;span class="w"&gt; &lt;/span&gt;~/modules&lt;span class="w"&gt; &lt;/span&gt;&amp;lt;B&amp;gt;:~/kernel/modules/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;On machine B:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;Cd&lt;span class="w"&gt; &lt;/span&gt;~/kernel/modules
tar&lt;span class="w"&gt; &lt;/span&gt;-xvzf&lt;span class="w"&gt; &lt;/span&gt;modules
sudo&lt;span class="w"&gt; &lt;/span&gt;mv&lt;span class="w"&gt; &lt;/span&gt;~/kernel/modules/3.16.43-SS&lt;span class="w"&gt; &lt;/span&gt;/lib/modules/
sudo&lt;span class="w"&gt; &lt;/span&gt;cp&lt;span class="w"&gt; &lt;/span&gt;~/kernel/boot/*&lt;span class="w"&gt; &lt;/span&gt;/boot/
sudo&lt;span class="w"&gt; &lt;/span&gt;rm&lt;span class="w"&gt; &lt;/span&gt;/boot/initrd.img-3.16.43-SS
sudo&lt;span class="w"&gt; &lt;/span&gt;update-initramfs&lt;span class="w"&gt; &lt;/span&gt;-c&lt;span class="w"&gt; &lt;/span&gt;-k&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;.16.43-SS
sudo&lt;span class="w"&gt; &lt;/span&gt;update-grub


&lt;span class="c1"&gt;#And… reboot!&lt;/span&gt;
Sudo&lt;span class="w"&gt; &lt;/span&gt;reboot&lt;span class="w"&gt; &lt;/span&gt;now
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h1&gt;&lt;a name="jemalloc" href="#jemalloc"&gt;JeMalloc &lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Do a git clone.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;./autogen.sh&lt;span class="w"&gt; &lt;/span&gt;
./configure&lt;span class="w"&gt; &lt;/span&gt;--enable-prof&lt;span class="w"&gt; &lt;/span&gt;--enable-stats&lt;span class="w"&gt; &lt;/span&gt;--enable-debug
Make


&lt;span class="o"&gt;[&lt;/span&gt;sharath.g@osboxes&lt;span class="w"&gt; &lt;/span&gt;/home/sharath.g/code/jemalloc&lt;span class="o"&gt;]&lt;/span&gt;$&lt;span class="w"&gt; &lt;/span&gt;tree&lt;span class="w"&gt; &lt;/span&gt;lib&lt;span class="w"&gt; &lt;/span&gt;
lib
├──&lt;span class="w"&gt; &lt;/span&gt;libjemalloc.a
├──&lt;span class="w"&gt; &lt;/span&gt;libjemalloc_pic.a
├──&lt;span class="w"&gt; &lt;/span&gt;libjemalloc.so&lt;span class="w"&gt; &lt;/span&gt;-&amp;gt;&lt;span class="w"&gt; &lt;/span&gt;libjemalloc.so.2
└──&lt;span class="w"&gt; &lt;/span&gt;libjemalloc.so.2

&lt;span class="c1"&gt;#To generate the profile:&lt;/span&gt;
&lt;span class="o"&gt;(&lt;/span&gt;reverse-i-search&lt;span class="o"&gt;)&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;java&lt;span class="s1"&gt;&amp;#39;: rm jeprof*; rm /tmp/prof.gif; MALLOC_CONF=prof:true,lg_prof_sample:0,lg_prof_interval:25 LD_PRELOAD=${JEMALLOC_PATH}/lib/libjemalloc.so.2 java -Xmx1096m -cp  &amp;#39;&lt;/span&gt;/home/sharath.g/diskbench/:/home/sharath.g/diskbench/*&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;sha.Memory&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;ls&lt;span class="w"&gt; &lt;/span&gt;jeprof*&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;~/code/jemalloc/bin/jeprof&lt;span class="w"&gt; &lt;/span&gt;--show_bytes&lt;span class="w"&gt; &lt;/span&gt;--gif&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;which&lt;span class="w"&gt; &lt;/span&gt;java&lt;span class="sb"&gt;`&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;jeprof*.heap&lt;span class="w"&gt; &lt;/span&gt;&amp;gt;&lt;span class="w"&gt; &lt;/span&gt;/tmp/prof.gif&lt;span class="w"&gt; &lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;If you’ve compiled jemalloc on some other machine and copied it to this machine, youget teh error Can't exec "objdump": No such file or directory at /home/sharath.g/jemalloc/bin/jeprof line 4459.
Then objdump is 
Jemalloc what is active, dirty (unused), resident, total memory, allocated, mapped?
Allocated = sum of all malloc arguments that has not been freed 
Active .. multiple of page size.. Total bytes in pages that have at least one byte of allocated memory
Resident: active + metadata 
Mapped: multiple of chunk size. Total chunks that have one byte of allocated 
See that man pages for a clear explanation.&lt;/p&gt;
&lt;h1&gt;&lt;a name="objdump" href="#objdump"&gt;Objdump&lt;/a&gt;&lt;/h1&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;objdump&lt;span class="w"&gt; &lt;/span&gt;-drSt&lt;span class="w"&gt; &lt;/span&gt;hello.o
-d&lt;span class="w"&gt; &lt;/span&gt;dissasemble
-r&lt;span class="w"&gt; &lt;/span&gt;show&lt;span class="w"&gt; &lt;/span&gt;relocation&lt;span class="w"&gt; &lt;/span&gt;info&lt;span class="w"&gt; &lt;/span&gt;inline
-S&lt;span class="w"&gt; &lt;/span&gt;show&lt;span class="w"&gt; &lt;/span&gt;C&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;source&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;code
-t&lt;span class="w"&gt; &lt;/span&gt;show&lt;span class="w"&gt; &lt;/span&gt;symbol&lt;span class="w"&gt; &lt;/span&gt;table
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h1&gt;&lt;a name="installing-latest-version-of-cmake" href="#installing-latest-version-of-cmake"&gt;Installing latest version of cmake&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Either apt-get install cmake or get it from here
https://cmake.org/download/
https://cmake.org/files/v3.8/cmake-3.8.0-rc4-Linux-x86_64.sh and run it&lt;/p&gt;
&lt;h1&gt;&lt;a name="getting-honest-profiler-to-work" href="#getting-honest-profiler-to-work"&gt;Getting honest profiler to work&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Installing it: 
If you’re lucky, you can download it and it works http://insightfullogic.com/honest-profiler.zip&lt;/p&gt;
&lt;p&gt;Otherwise you need to build it. To build it, if you get weird errors, you might need to get latest version of Cmake, and then build it. You need build/libagent.so&lt;/p&gt;
&lt;p&gt;Start the java program with     &lt;br&gt;
&lt;code&gt;-agentpath:$HONEST_PROFILER_HOME/liblagent.so=host=localhost,port=4242,logPath=/grid/1/log/hadoop-yarn/yarn/honest-profiler.hpl&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Start and stop profiling with &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;start&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;nc&lt;span class="w"&gt; &lt;/span&gt;localhost&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;4242&lt;/span&gt;
&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;stop&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;nc&lt;span class="w"&gt; &lt;/span&gt;localhost&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;4242&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Collapse the stacks with &lt;code&gt;java -cp $HONEST_PROFILER_HOME/honest-profiler.jar com.insightfullogic.honest_profiler.ports.console.FlameGraphDumperApplication netty.hpl netty.cstk&lt;/code&gt;&lt;/p&gt;
&lt;h1&gt;&lt;a name="gcc-important-options" href="#gcc-important-options"&gt;GCC important options&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;The linker &lt;code&gt;ld&lt;/code&gt; takes as input .c files, .o files, .so files and can output an executable or a shared library.
The linker does not output static library. You can simply use ar for it&lt;/p&gt;
&lt;p&gt;Gcc important options
-l mylib 
Look for a library called libmylib.{a, so}
But if both are present, will it choose .a or .so (it chooses .so) if you want to link an .a file, specify it directly on the command line. Or specify -static so it will choose .a even for libc &lt;/p&gt;
&lt;p&gt;Which directories to look in ?
-L dir is the answer&lt;/p&gt;
&lt;p&gt;-i dir is for searching include files 
-include file
Is as if file was #included in source code in the first line. &lt;/p&gt;
&lt;p&gt;So basically &lt;code&gt;-L dir -l mylib -I dir -include files&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;When creating an executable:
You cannot link a shared library statically by giving it on the command line (to create an executable) even if you give on command line, it still links it as  a shared library (as if you had given -L. -lxxx)
Or you cannot link a static library in a shared way by using -L and -l options (to create an executable)(you can but it will be taken as static, even if the static library is named libxx.so) &lt;/p&gt;
&lt;p&gt;Static libraries can be linked (statically) by specifying them as input files to gcc. Remember: static libraries are just a bunch of .o files 
You cannot skip specifying a shared library while linking to create an executable (although, technically they are not needed)  all variables must be resolved, which means that all shared libraries have to be specified (strictly not required, i guess its a sanity check) this has the effect of  listing in the executable as a dependency     &lt;/p&gt;
&lt;p&gt;For &lt;code&gt;LD_PRELOAD&lt;/code&gt; to work, you have to specify -Wl,-soname,libml.so while having created that shared library this name is hardcoded into the so as its name, and this is the name that the linker looks at while loading the executable, not the file name of the .so&lt;/p&gt;
&lt;h1&gt;&lt;a name="when-creating-a-shared-library:" href="#when-creating-a-shared-library:"&gt;When creating a shared library:&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;All object files must be compiled with -fpic
All ar files must have .o files which have been compiled with -fpic
If you specify multiple .so on command line, they will be combined into 1 .so as expected, with references resolved internally 
If a dependency is unmet (by not specifying some libraries at all) it is defined as undefined but linking succeeds
If a dependency is met by -L. -lxxx then it is undefined in the .so but that lib is listed as a dependency&lt;/p&gt;
&lt;h1&gt;&lt;a name="eli-bendersky-static-linking-summary" href="#eli-bendersky-static-linking-summary"&gt;Eli bendersky static linking summary&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Static linking algorithm perfectly explained in http://eli.thegreenplace.net/2013/07/09/library-order-in-static-linking
Some important points
* An object file both exports and imports symbols 
* individual object files specified on cmd line are always linked
* static libraries (ar) libraries serve only to provide a list of object files, and an object file in a library is linked only if it satisfies some current unmet dependency &lt;/p&gt;
&lt;h1&gt;&lt;a name="eli-bendersky-load-time-linking-summary" href="#eli-bendersky-load-time-linking-summary"&gt;Eli bendersky load time linking summary&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Summary of load time linking as specified in http://eli.thegreenplace.net/2011/08/25/load-time-relocation-of-shared-libraries&lt;/p&gt;
&lt;p&gt;Some gotchas: 
* Call operands are rip relative, but mov operands are absolute. In x86_64, there is a new addressing called RIP relative where any operand can be RIP relative.
* If a shared variable in a .so is referenced from the main executable, then that shared variable will go into the main executable, since the main executable is not relocatable. 
* what about a shared function in a .so referenced from main executable? The article does not mention it, but i imagine the functionality is similar. I.e. put the address of the function in the main program during load time and then call it.&lt;/p&gt;
&lt;p&gt;Basically the address where a shared library is loaded is unknown
The static linker generates .so as if the shared library is loaded at 0x0 (logical)
The linker tells the offset of each variable in the file. 
The loader will add this offset to the load address to get the real address
The linker also populates a list where the real address has to be patched into the code. 
The loader will then patch the addresses in
Thats it.&lt;/p&gt;
&lt;h1&gt;&lt;a name="eli-bendersky-x32-pic-linking-summary" href="#eli-bendersky-x32-pic-linking-summary"&gt;Eli bendersky x32 PIC linking summary&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;http://eli.thegreenplace.net/2011/11/03/position-independent-code-pic-in-shared-libraries&lt;/p&gt;
&lt;p&gt;Instead of direct patching in the code, the real addresses of shared variables are stored in a GOT table in the data section. 
For mov operands, x32 does not support rip relative addresses, so there is a hack to get current rip address, then add the offset of the got table, and thus get the address of the variable&lt;/p&gt;
&lt;p&gt;For call instructions, they are still using the hack but call supports rip relative addressing. So not sure what is happening,&lt;/p&gt;
&lt;h1&gt;&lt;a name="linux-interrupt-handling" href="#linux-interrupt-handling"&gt;Linux Interrupt Handling&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Peripheral devices pass interrupt to the interrupt controller (8259) which then passes it to processor on a given interrupt line.
An Interrupt line can be shared by multiple devices. To detect which device raised the interrupt, the linux interrupt handler iterates through all registered handlers on that line which then checks if that device raised the interrupt.
When an interrupt is raised, the processor disables all interrupts (on the local processor). 
The linux handler reenables interrupts (unless a flag was set while registering the handler) but disables the interrupt line (so none of the devices sharing can raise another interrupt) and calls the handler. For this reason, an interrupt handler need not be re-entrant. 
An interrupt handler cannot sleep/block because there is no “process” to sleep or block. (theoretically, the process can be considered to be the process that was interrupted but seems like a design decision to not let interrupt handlers sleep or not associate interrupt handlers with a process.&lt;/p&gt;
&lt;h1&gt;&lt;a name="hdfs-proxy-user-setting" href="#hdfs-proxy-user-setting"&gt;HDFS proxy user setting&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;In addition to the modifications in core-site.xml we need to create the user and (add it to a group (?)) on the namenode. Even this is not working. It looks like the user needs to be added on the datanodes too. Is this true?
The logs from namenode are like this: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;2017-06-05 11:48:27,271 INFO  ipc.Server (Server.java:doRead(850)) - Socket Reader #1 for port 8020: readAndProcess from client 10.32.10.3 threw exception [org.apache.hadoop.security.authorize.AuthorizationException: Unauthorized connection for super-user: hue from IP 10.32.10.3]
The ip 10.32.10.3 is a datanode.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h1&gt;&lt;a name="http-proxy-with-squid" href="#http-proxy-with-squid"&gt;Http proxy with squid&lt;/a&gt;&lt;/h1&gt;
&lt;h3&gt;On the client machine&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Find out the client subnet of the form &lt;code&gt;10.34.44.0/22&lt;/code&gt;. To do that, on the client machine, run &lt;code&gt;/sbin/ifconfig&lt;/code&gt; to find out the       ip address and subnet mask. with these two pieces of info, you can calculate the CIDR &lt;a href="http://www.subnet-calculator.com/cidr.php"&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;export variables: 
  &lt;code&gt;text
  export http_proxy=http://client.ip.ad.ress:port/
  export https_proxy=http://client.ip.ad.ress:port/&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Caveat&lt;/h3&gt;
&lt;p&gt;if you run sudo, make sure the variables are exported in root&lt;/p&gt;
&lt;h3&gt;On the proxy machine&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Install squid: &lt;code&gt;sudo apt-get install squid&lt;/code&gt;. &lt;/li&gt;
&lt;li&gt;
&lt;p&gt;change /etc/squid/squid.conf to add these lines
   &lt;code&gt;text
   acl wormhole src 10.34.44.0/22 # the client subnet who need the proxy
   http_access allow wormhole # wormhole is just a name
   icp_access allow wormhole&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;restart squid &lt;code&gt;sudo /etc/squid/squid.conf restart&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And thats it! &lt;code&gt;curl -L www.google.com&lt;/code&gt; (&lt;code&gt;-L&lt;/code&gt; to follow redirects) will work.&lt;/p&gt;
&lt;p&gt;I needed this for &lt;code&gt;pip&lt;/code&gt;. With my setup, I can do &lt;code&gt;sudo export &amp;lt;blah&amp;gt;;export&amp;lt;blah&amp;gt;;pip install &amp;lt;package&amp;gt;&lt;/code&gt;. &lt;/p&gt;
&lt;p&gt;FYI, my squid version is&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;[sharath.g@d42-a-0003 /home/sharath.g]$ dpkg -s squid
Package: squid
Status: install ok installed
Priority: optional
Section: web
Installed-Size: 1864
Maintainer: Luigi Gangitano &amp;lt;luigi@debian.org&amp;gt;
Architecture: amd64
Version: 2.7.STABLE9-4.1+deb7u1
Replaces: squid-novm
Depends: libc6 (&amp;gt;= 2.7), libcomerr2 (&amp;gt;= 1.01), libdb5.1, libgssapi-krb5-2 (&amp;gt;= 1.10+dfsg~), libkrb5-3 (&amp;gt;= 1.6.dfsg.2), libldap-2.4-2 (&amp;gt;= 2.4.7), libpam0g (&amp;gt;= 0.99.7.1), netbase, adduser, logrotate (&amp;gt;= 3.5.4-1), squid-common (&amp;gt;= 2.7.STABLE9-4.1+deb7u1), lsb-base (&amp;gt;= 3.2-14), perl-modules
Pre-Depends: debconf (&amp;gt;= 1.2.9) | debconf-2.0
Suggests: squidclient, squid-cgi, logcheck-database, resolvconf (&amp;gt;= 0.40), smbclient, winbind
Conflicts: sarg (&amp;lt;&amp;lt; 1.1.1-2), squid-novm
Conffiles:
 /etc/init.d/squid 04af7c1f2d27c35db0200679fbc9bdbe
 /etc/logrotate.d/squid 0dd1fea0f842a58f538408754e747311
 /etc/resolvconf/update-libc.d/squid f8d0ffa84ddd982f32da05cb61bc479e
Description: Internet object cache (WWW proxy cache)
 This package provides the Squid Internet Object Cache developed by
 the National Laboratory for Applied Networking Research (NLANR) and
 Internet volunteers.
Homepage: http://www.squid-cache.org/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h1&gt;&lt;a name="kafka-metrics" href="#kafka-metrics"&gt;kafka metrics&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Bytes in&lt;/strong&gt; is number of bytes from external producers only. It does not include, for example, the bytes read by followers during replication. So &lt;code&gt;bytes_in = message_produce_rate * average_message_size&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Bytes out&lt;/strong&gt; includes data sent to follower also.&lt;/p&gt;</content><category term="misc"></category><category term="misc"></category></entry><entry><title>The quest for high throughput RPC</title><link href="/the-quest-for-high-throughput-rpc.html" rel="alternate"></link><published>2018-07-07T00:30:00+00:00</published><updated>2018-07-07T00:30:00+00:00</updated><author><name>Sharath Gururaj</name></author><id>tag:None,2018-07-07:/the-quest-for-high-throughput-rpc.html</id><summary type="html">&lt;p&gt;In this post, I compare the rpc throughput of some existing RPC frameworks and talk about a new technique of doing RPC . Dropwizard on a single connection gives around &lt;code&gt;1000 req/sec&lt;/code&gt;, whereas a prototype implementation of this technique gives around &lt;code&gt;4 million req/sec&lt;/code&gt; for a “hello world” rpc …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In this post, I compare the rpc throughput of some existing RPC frameworks and talk about a new technique of doing RPC . Dropwizard on a single connection gives around &lt;code&gt;1000 req/sec&lt;/code&gt;, whereas a prototype implementation of this technique gives around &lt;code&gt;4 million req/sec&lt;/code&gt; for a “hello world” rpc&lt;/p&gt;
&lt;p&gt;Lots of companies these days use a microservices architecture, where the application as a whole is split into multiple smaller microservices communicating over the network. What follows in the post is heavy on numbers, which admittedly is boring to parse and makes it a little dry. A nanosec, microsec and a millisec might all just seem like a really small amount of time for humans but the distance between them is vast. If we were to blow up the numbers to human scale and make a nanosec as a second, then it would take one nanosec to pick up a pen next to your laptop, one microsec is a 20 min bike ride, and 1 millisec is a bike ride from bangalore to indore!&lt;/p&gt;
&lt;p&gt;For the time being, I’m going to consider two communicating processes on localhost so we don’t have to worry about network transmission latency for now
Our goal is to exchange 100 byte messages as fast as we can between two processes with a cap on (say 95% percentile) latency (say, &lt;code&gt;&amp;lt;5 ms&lt;/code&gt;)&lt;/p&gt;
&lt;h2&gt;Dropwizard and web services&lt;/h2&gt;
&lt;p&gt;If we hook up a simple dropwizard app with a “hello world” GET api and hit it with apache bench (ab) on localhost laptop with a single connection, I get around &lt;code&gt;1000 req/sec&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;If I pump up the number of concurrent connections, I get around &lt;code&gt;7000 req/s&lt;/code&gt; with around 100 connections (I hit ulimit after that on mac).&lt;/p&gt;
&lt;p&gt;How good or bad is that?&lt;/p&gt;
&lt;p&gt;For an absolute theoretical limit, we can compare it to the rate at which CPUs can read and write streaming data to/from memory. From my measurements, each core can stream data from RAM at around 1GB/sec.
so 1GBps means 10 million req/s with 100 byte messages. When compared to the 800 req/s for a single connection, this is disappointing indeed.&lt;/p&gt;
&lt;p&gt;Of course, dropwizard does a lot more than simply stream data to/from memory. It has to parse http, send the packet down on the tcp stack and do the whole thing back on the rx side.&lt;/p&gt;
&lt;p&gt;So how much time does it take for a packet to traverse the tcp stack? I’ve measured that it takes around ~25 microseconds ballpark to go down or come up the tcp stack. This is also in agreement with some online benchmarks. If we take this into account, it should take around 1/(50 usec) or ~2000 req/sec per core (pair). Compared to this, 800 req/s seems to be a bit too slow, even with the added http parsing.&lt;/p&gt;
&lt;p&gt;With multiple cores and a large number of connections, I was able to crank up dropwizard to around 20K req/sec, but it requires many 100’s of connections to parallelize the processing. But keeping in mind the 10 million req/sec, this is still disappointing&lt;/p&gt;
&lt;p&gt;The problem with using jetty/dropwizard for RPC is that, fundamentally, the architectures these web servers are tuned for entirely different things. Web servers are meant to operate on the internet, where a server can hold many tens of thousands of browser connections, with each browser connection being mostly idle and bursty for a short while. This does not map well to a Data Center environment where a server is talking to only about a dozen other services, and the connections are long lived and required to be very high throughput.&lt;/p&gt;
&lt;p&gt;I believe this is causing a systemic performance problem in software companies. For example, we are all aware that disk and database access is orders of magnitude slower than cpu/network. Why then do we put ~20 dropwizard boxes in front of a mysql DB? Shouldn’t it be the other way round? 1 (or a few for redundancy) dropwizard box fronting multiple sharded mysql instances? This webserver problem leads to a vicious cycle: Each client needs to also employ multiple boxes just to generate the paralellism and connections to load a server.&lt;/p&gt;
&lt;p&gt;The summary so far:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;type&lt;/th&gt;
&lt;th&gt;throughput&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;dropwizard single connection&lt;/td&gt;
&lt;td&gt;1000 req/s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;dropwizard 100 connections&lt;/td&gt;
&lt;td&gt;7000 req/s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;TCP packet round trip&lt;/td&gt;
&lt;td&gt;20k req/s (ballpark)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CPU streaming from RAM&lt;/td&gt;
&lt;td&gt;10M req/s&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;Unix domain sockets&lt;/h2&gt;
&lt;p&gt;Anyway, to continue with our quest for high throughput, lets skip web servers altogether.&lt;/p&gt;
&lt;p&gt;With Unix domain sockets (which works only on localhost), we can bypass the entire tcp stack and take a much shorter route through the kernel. With UDS and a netty server (the default implementation in specter), we have measured around 10K req/s on a single core. Compare this to 800 req/s for dropwizard and 20K req/s if we were to traverse the TCP stack). With all cores (~10 cores), I measured around 40K req/s. This is much better than web servers. But still slow, considering
* we’re skipping the entire tcp stack
* the 1GBps CPU-memory bandwidth&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;type&lt;/th&gt;
&lt;th&gt;throughput&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;UDS single connection&lt;/td&gt;
&lt;td&gt;10K req/s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;UDS multiple connections&lt;/td&gt;
&lt;td&gt;40K req/s&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;Grpc and HTTP2&lt;/h2&gt;
&lt;p&gt;Another fundamental problem with all the previous frameworks are that they operate in inherently thread-request-response modes. i.e., the client thread sends a request and waits for a response. We would be able to achieve much better results if we operate in streaming mode, where the client is streaming multiple requests and the server is streaming back multiple responses. For this, we use HTTP2. It has two big advantages, the wire format is binary (not textual like HTTP) and it supports request streaming/pipelining&lt;/p&gt;
&lt;p&gt;gRPC is a RPC mechanism using HTTP2. I haven’t explicitly measured the performance but according to the available online bencharks, they are able to do around 300K req/sec across two different machines, (which I assume will fall to ~150K) with both client and server on localhost.&lt;/p&gt;
&lt;p&gt;Newer versions of jetty also support HTTP2. I tested out with a barebones embedded HTTP2 jetty server and I was able to get ~40K req/sec which is comparable to the UDS performance. Although less than gRPC, This is impressive considering that jetty has to parse HTTP as well as traverse the tcp stack, which UDS avoids. (Also remember that UDS is operating in request-response mode, not streaming mode)&lt;/p&gt;
&lt;h2&gt;Raw sockets&lt;/h2&gt;
&lt;p&gt;All this begs the question: what is the fundamental limit for streaming data across a TCP connection? I threw up a small experiment with raw sockets in java on localhost and to my surprise, I was able to get the full 1GBps even with the tcp stack. Then where are we going wrong? why aren’t we able to achieve this with existing frameworks and even with http2?
When I was running the TCP streaming test, I realized that the key to high throughput is batching. The cost of traversing the tcp stack is roughly the same whether we send 1 byte or 1kB or 1MB. This is very apparent in the tests. With small messages, the throughput is approx 10K req/s. As we double the message size, the throughput keeps doubling, until it reaches 1GBps. So it makes sense to introduce a small “linger” time to combine multiple messages and send it across at once. How big is “big” for TCP networks? From the tests, I found that ~ 10Kb payload size is able to saturate the network (and memory) line rates&lt;/p&gt;
&lt;p&gt;None of the RPC frameworks that I know of employ this technique. Actually, Kafka producer employs batching but suffers from other architectural issues which prevents it from achieving full line rate (More on that in a future post). In fact, the trend is in the opposite direction, to reduce message latencies further and send across a message as soon as possible. For example, Aeron claims to reduce latency from 50 microsec to 30 microsec by using UDP. The latency improvement might be super important in finance but presents only a very marginal improvements in throughput.&lt;/p&gt;
&lt;h2&gt;The new and shiny&lt;/h2&gt;
&lt;p&gt;I wrote a client and a server which uses this batching technique over raw sockets. I batch small messages together until they reach a size of 20KB (or a timeout expires) and send big batches (~20kb) over tcp. The results were quite astounding. I was able to reach 3 million req/sec with 100 byte messages and only a single tcp connection and a single core (pair).&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;type&lt;/th&gt;
&lt;th&gt;throughput&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;gRPC&lt;/td&gt;
&lt;td&gt;150K req/s (haven't tested)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Jetty HTTP2 server with async client and req pipelining&lt;/td&gt;
&lt;td&gt;40K req/s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Aeron&lt;/td&gt;
&lt;td&gt;30K req/s&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The code has almost no micro-optimizations (like object cache, zero copy, connection pools, etc) but it demostrates the effectiveness of this architecture.I am a little blown away by how much the throughput increasing with a simple technique. The best news is that the throughput remains virtually unaffected even over a 10Gbps network
If you’re interested in checking out the code and trying it out on localhost or in our DC, here is the link.
https://github.com/agsha/sharpc&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;type&lt;/th&gt;
&lt;th&gt;throughput&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;span style="color:red"&gt;New Batching RPC single TCP connection&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;3M req/s (haven't tested)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Dropwizard/jetty has a well understood and rock solid programming model, but leaves a lot to be desired with respect to max throughput achievable.&lt;/li&gt;
&lt;li&gt;Enabling HTTP2 is quite trivial for Jetty and can be expected to fetch ~30–50% increase in throughput&lt;/li&gt;
&lt;li&gt;Maybe its time to consider a “true” RPC subsystem in software companies: like grpc or thrift&lt;/li&gt;
&lt;li&gt;A batching algorithm can increase throughput by orders of magnitude compared to even high performance frameworks like grpc
and here’s a cat of all the previous tables&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;type&lt;/th&gt;
&lt;th&gt;throughput&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;dropwizard single connection&lt;/td&gt;
&lt;td&gt;1000 req/s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;dropwizard 100 connections&lt;/td&gt;
&lt;td&gt;7000 req/s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;TCP packet round trip&lt;/td&gt;
&lt;td&gt;20k req/s (ballpark)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CPU streaming from RAM&lt;/td&gt;
&lt;td&gt;10M req/s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;UDS single connection&lt;/td&gt;
&lt;td&gt;10K req/s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;UDS multiple connections&lt;/td&gt;
&lt;td&gt;40K req/s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;gRPC&lt;/td&gt;
&lt;td&gt;150K req/s (haven't tested)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Jetty HTTP2 server with async client and req pipelining&lt;/td&gt;
&lt;td&gt;40K req/s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Aeron&lt;/td&gt;
&lt;td&gt;30K req/s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;span style="color:red"&gt;New Batching RPC single TCP connection&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;3M req/s (haven't tested)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;</content><category term="misc"></category><category term="misc"></category></entry><entry><title>A bangalore software engineer's first trip to Bali</title><link href="/a-bangalore-software-engineers-first-trip-to-bali.html" rel="alternate"></link><published>2016-06-23T00:30:00+00:00</published><updated>2016-06-23T00:30:00+00:00</updated><author><name>Sharath Gururaj</name></author><id>tag:None,2016-06-23:/a-bangalore-software-engineers-first-trip-to-bali.html</id><summary type="html">&lt;p&gt;I have just returned from a 8 day trip to Bali. Here are some tips and info, fresh off my mind. These are points that I wish I knew before my trip to Bali, and the tips that I never came across online or on tripadvisor reviews.&lt;/p&gt;
&lt;h3&gt;Flight&lt;/h3&gt;
&lt;p&gt;If you're …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I have just returned from a 8 day trip to Bali. Here are some tips and info, fresh off my mind. These are points that I wish I knew before my trip to Bali, and the tips that I never came across online or on tripadvisor reviews.&lt;/p&gt;
&lt;h3&gt;Flight&lt;/h3&gt;
&lt;p&gt;If you're leaving from bangalore, then consider going first to kochi or chennai, and then going to Bali. It worked out cheaper for me. Flight from Blore to kochi was ~ INR 1000 and flight from kochi to Bali was ~ INR 15000. A direct flight from Blore to Bali was in comparison around INR 24000. An aside: airport food is annoyingly expensive and not good at all. Strongly recommend &lt;em&gt;packing&lt;/em&gt; enough food to last you till your destination --- including layovers. &lt;/p&gt;
&lt;p&gt;If you're travelling in Air Asia, beware! They're the stingiest aircraft I've ever flown in. They don't even offer water for free, even on international routes. Let alone food. Furthermore, &lt;strong&gt;check-in baggage is not free!&lt;/strong&gt; it cost me around 5000 Rupees extra for one piece of check-in luggage. Oh, yes. If you forget to call and pay for check-in baggage before hand, then the cost is &lt;em&gt;really&lt;/em&gt; exorbitant if you check-in at the airport counter.&lt;/p&gt;
&lt;h3&gt;Visa requirements for indians&lt;/h3&gt;
&lt;p&gt;This was the best part about the Bali trip. &lt;strong&gt;Bali has FREE visa-on-arrival for indians!&lt;/strong&gt; Furthermore, they asked almost NO documents. He simply took one look at my passport and stamped "visa approved for 6 months". Even the immigration wait line was non-existent. The whole immigration process took around 2 minutes. Very pleasant experience.&lt;/p&gt;
&lt;h3&gt;Currency conversion&lt;/h3&gt;
&lt;p&gt;Take USD to Bali, not INR. None of the banks I saw exchanged INR for IDR (Indonesian rupiah). On the other hand, literally every other street has 'money changing' shops which changes USD to IDR (And they are legit). I strongly recommend buying dollars. &lt;/p&gt;
&lt;p&gt;I also had my ICICI debit card that worked pretty seamlessly in Bali. I called up ICICI beforehand that I would be using it in Bali. The card was declined in a couple of shops but accepted at around 90% of the shops. I could also draw IDR from most ATMS. For transaction in shops, ICICI charges 3% + competitive currency conversion. For ATM cash withdrawal, ICICI charges INR 125 + 3% of money withdrawn. Most services in Bali don't accept cards. So whenever you can use the card, use it.&lt;/p&gt;
&lt;p&gt;Something that I did not do, but I should have is that I should have checked with ICICI what happens in the even I lose my debit card and am short of cash. &lt;/p&gt;
&lt;h3&gt;Getting around in Bali&lt;/h3&gt;
&lt;p&gt;Bali is a pretty small place. Most places are within an hour or two driving distance. Definitely get a rental motorbike in Bali. Its super convenient. They charge ~INR 300 per day of rental. Public transportation is almost non existant from what I saw. Although, legally, you need an international driving license to ride a motorbike, It is generally tolerated. Even when caught by the police, the fines are low. Around INR 500. I got caught by the police once: when I was driving on the
wrong direction of a one way. I paid around INR 500 as fine and the police dusted my bike seat and showed me the direction to my destination and helped me along the way. You can see firangs (obviously not Balinese) zipping along in bikes all over Bali. &lt;/p&gt;
&lt;h3&gt;Bargain hard&lt;/h3&gt;
&lt;p&gt;Every service in Bali is overpriced, and it is expected that you bargain. Usually you can get a 35% - 50% reduction in the quoted price. Balinese are very friendly (and sympathetic) towards indians as compared to firangs and it is possible to strike better deals than what firangs can manage. So don't be shy to ask for a discount. &lt;/p&gt;
&lt;h3&gt;Names and the caste system in Bali.&lt;/h3&gt;
&lt;p&gt;There are only four first names in Bali: Ketut, komang, wayan, Made (pronounced Madi). The way it works is:
Let &lt;code&gt;String[] A = {"Ketut", "komang", "wayan", "Made"}&lt;/code&gt; be a string array where the index is 0-based. i.e., &lt;code&gt;A[0]&lt;/code&gt; is &lt;code&gt;"ketut"&lt;/code&gt;. Now if you're the &lt;code&gt;x&lt;/code&gt; &lt;sup&gt;th&lt;/sup&gt; eldest son (where the eldest son is &lt;code&gt;1&lt;/code&gt;, and so on), then your first name is &lt;code&gt;A[(x-1)%4]&lt;/code&gt;. The last name of course is different. Curiously though, people always tell their first name (one of the four said names) when you ask them their name. &lt;/p&gt;
&lt;h3&gt;Telephone SIM card and 3G&lt;/h3&gt;
&lt;p&gt;The very first thing you should do when you land is Bali is: you should get a local SIM card with a 3G data limit of ~2GB.&lt;/p&gt;
&lt;p&gt;3G Coverage in Bali is excellent and google maps is your friend in Bali. Oh yeah. &lt;strong&gt;Definitely carry a extra battery pack (or power pack) for your cell phone&lt;/strong&gt;. Its a life saver. This was easily the most important thing I carried to Bali&lt;/p&gt;
&lt;h3&gt;Places to visit.&lt;/h3&gt;
&lt;p&gt;If this is your first time in Bali, then from an indian point of view, and depending on how long you're planning to visit, this is your order of priority for places to stay. &lt;/p&gt;
&lt;h4&gt;Seminyak&lt;/h4&gt;
&lt;p&gt;Total party area with nice beaches and shopping, also accessible to other places like Uluwatu temple in the south and Tanah lot in the north. (No trip to Bali is complete without a visit to these two). Catch the sunset in both places. Its breathtaking. I did explore three or four beaches but I didnt like most of them. For example, kuta beach doesnt have a lot of 'beach' area (The distances from where the waves end to where the roads begin). Sanur beach totally sucked. It has white sands but
its gravelly and rocky. Very uncomfortable. Beti-balug beach in seminyak has nice sand but not so popular and seems a little ghetto. The only one I liked was double-six beach. Its got everything. Beach chairs, soft sand, lots of restaurants nearby and tons of activities. Perfect for spending an entire day.&lt;/p&gt;
&lt;h4&gt;Ubud&lt;/h4&gt;
&lt;p&gt;Best place to stay is right next to monkey forest. Very cultural place and worth exploring the 'non-beachy' side of Bali. From there you can explore other areas in and near ubud, like tagalalong rice terrace, tegunnen water falls etc.&lt;/p&gt;
&lt;h4&gt;Nusa Penida&lt;/h4&gt;
&lt;p&gt;Little off the main touristy spot (its a separate island). I never visited it but I wish I had. Its got lots of stuff to do according to &lt;a href="https://indonesia.tripcanvas.co/bali/unique-places-in-bali/page/3/"&gt;this link&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Voltage specs in Bali&lt;/h3&gt;
&lt;p&gt;Bali uses the same kind of round pins that we use in india. Not the flat rectangular pins from US. But one major problem: The socket is "hollow" &lt;a href="https://www.tripadvisor.com/LocationPhotoDirectLink-g1465999-d1539040-i79297910-The_Wangsa_Private_Estate-Tanjung_Benoa_Nusa_Dua_Peninsula_Bali.html"&gt;like this&lt;/a&gt;. So if your charger body is bulky, it won't fit inside the hollowness of the sockets. None of my chargers from india fit in the socket. Luckily every airbnb that I stayed had a Bali adapter
or a Bali charger that allowed me to charge.&lt;/p&gt;
&lt;h3&gt;Cost of the trip.&lt;/h3&gt;
&lt;p&gt;This will of course vary a lot for person to person so your mileage may vary. The numbers are for two people for 8 days.
The costs below are &lt;em&gt;excluding&lt;/em&gt; hotel bookings and flights.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Type&lt;/th&gt;
&lt;th&gt;Cost&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;transport&lt;/td&gt;
&lt;td&gt;Rs 10,200&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;entertainment&lt;/td&gt;
&lt;td&gt;Rs 25,000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;food&lt;/td&gt;
&lt;td&gt;Rs 16,000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;shopping&lt;/td&gt;
&lt;td&gt;Rs 17,000&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The excrutiangly detailed breakup of costs is &lt;a href="https://docs.google.com/spreadsheets/d/1uVaI5bQ702zNCqu6tZL-GoIzKm4CGlxRkincuRJys5k/edit?usp=sharing"&gt;here&lt;/a&gt;&lt;/p&gt;</content><category term="misc"></category><category term="misc"></category></entry><entry><title>The affair between iostat and fio</title><link href="/the-affair-between-iostat-and-fio.html" rel="alternate"></link><published>2016-06-02T16:20:00+00:00</published><updated>2016-06-02T16:20:00+00:00</updated><author><name>Sharath Gururaj</name></author><id>tag:None,2016-06-02:/the-affair-between-iostat-and-fio.html</id><summary type="html">&lt;p&gt;In the following analysis, I'm going to assume you already know what &lt;code&gt;fio&lt;/code&gt; and &lt;code&gt;iostat&lt;/code&gt; is (I'm too lazy to write it down, and there are better articles out there). This post merely explains the relationship between the numbers&lt;/p&gt;
&lt;h3&gt;fio output&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;io = bw*runt
io = iops*runt*bs
issued(r …&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;In the following analysis, I'm going to assume you already know what &lt;code&gt;fio&lt;/code&gt; and &lt;code&gt;iostat&lt;/code&gt; is (I'm too lazy to write it down, and there are better articles out there). This post merely explains the relationship between the numbers&lt;/p&gt;
&lt;h3&gt;fio output&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;io = bw*runt
io = iops*runt*bs
issued(r) = iops*runt
io = ios*bs
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;iostat output&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;[sharath.g@prod-d42ar-osd-a-00079-423040 /home/sharath.g]$ iostat -x -d 2 /dev/vdb 
Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util
vdb               0.00     0.00  179.00    0.00   716.00     0.00     8.00     1.00    5.59    5.59    0.00   5.58  99.80
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;some inferences&lt;/h3&gt;
&lt;p&gt;From the line &lt;code&gt;read : io=78556KB, bw=670322 B/s, iops=163 , runt=120004msec&lt;/code&gt; 
we observe that &lt;code&gt;io = bw * runt&lt;/code&gt;. Makes sense.&lt;/p&gt;
&lt;h3&gt;units&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;bs = bytes&lt;/code&gt;, &lt;code&gt;io = KB&lt;/code&gt; &lt;code&gt;bw=KBps&lt;/code&gt;, &lt;code&gt;runt = ms&lt;/code&gt; &lt;code&gt;r/s=number&lt;/code&gt; &lt;code&gt;avrq-sz=sectors (=512 bytes)&lt;/code&gt;&lt;/p&gt;
&lt;h3&gt;libaio,read,sync=0,direct=0&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;bw = bs*iops&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;io = bs*iops*(runt/1000) / 1024&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;rKB/s = r/s * (avgrq-sz*512) / 1024&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Observe the &lt;code&gt;r/s&lt;/code&gt;, &lt;code&gt;rKB/s&lt;/code&gt; and &lt;code&gt;avrq-sz&lt;/code&gt; graphs. Its very interesting. until block size of 4kb, the &lt;code&gt;iops&lt;/code&gt; value remains constant at 175. After this size, the &lt;code&gt;avrq-sz&lt;/code&gt; starts doubling (the file system minimum block size is 4kb but it can increase that block size upto 0.5 mb when we are trying to read bigger blocks). So after bs=4kb, iops drops because there is some time required to do sequential reads as well. It hits a low at 512kb because reading 512kb is eating into the time for making random reads. Now the &lt;code&gt;avrq-sz&lt;/code&gt; maxes out. Now a single fio read requires more than one 'sequential low level reads' so &lt;code&gt;r/s&lt;/code&gt; now increases steadily. Until the point of 16mb where each fio read equals 32 sequential reads at the block layer. This results in very high &lt;code&gt;r/s&lt;/code&gt; and the corresponding &lt;code&gt;rKB/s&lt;/code&gt; shows sequential-like bandwidths. So far so good! If you see the &lt;code&gt;bw&lt;/code&gt; column, its doubling all the way from 1 byte to 512kb. Until 4kb block size this is caused by simply reading more from the 4k filesystem block that is already read anyway. From 4k to 512k, the doubling is caused due to the doubling of file system block size that is being read. You can see from 4k to 512k block size, the &lt;code&gt;bw&lt;/code&gt; pretty much matches with &lt;code&gt;rKB/s&lt;/code&gt;. But what the heck happened after 1MB block size?!?! &lt;code&gt;bw&lt;/code&gt; has shot upto 1.3 GB/s, while rBK/s continues to be around 70MBps range. The linux page cache is causing this. If you see the &lt;code&gt;rKB/s&lt;/code&gt; column, we are doing around 70MBps. We can read the entire 3GB file in &lt;code&gt;3000/70 = 42&lt;/code&gt; seconds. For the rest 18 seconds, the requests are served through ram and the iops and bw shoots through the roof. Also observe that this is the first time that the file could be read entirely into the page cache. Because, for the previous run with &lt;code&gt;2^19&lt;/code&gt; the value of rKB/s is around 50MBps. In 60 seconds, it just managed to (or missed to ) read &lt;code&gt;50*60sec = 3G&lt;/code&gt; file. So we didnt observe cache effects for the previous run. After 2^20, the bw still keeps increasing, probably because we are filling up the page cache earlier in each run (due to increase in &lt;code&gt;rKB/s&lt;/code&gt;) . Furthermore it seems like fio does a &lt;code&gt;drop-cache&lt;/code&gt; to clear the cache before every run (which is good for us). Now observe the &lt;code&gt;iops&lt;/code&gt; graph. After the spectacular shootup at 2^20, the iops keeps halving. This makes perfect sense because the requests are being served from ram. ram being truly random access, the bandwidth has to remain constant. So if you double the block size, the iops should halve. Sweet! &lt;/p&gt;
&lt;p&gt;Unexplained/TODO:
I tried to explain the &lt;code&gt;r/s&lt;/code&gt; graph in more quantitative terms. If my theory holds, then the V shape from 2^16 to 2^23 is caused by seek_time + sequential_throughput.
i.e. to read a block of &lt;code&gt;x kb&lt;/code&gt;, time taken should be &lt;code&gt;seek_time + sequential_throughput_sec_per_kb*x&lt;/code&gt;
Now you can actually calculate &lt;code&gt;seek_time&lt;/code&gt; and &lt;code&gt;sequential_throughput&lt;/code&gt; with the values at 2^17 and 2^18&lt;/p&gt;
&lt;p&gt;When you extrapolate it to other values, I get &lt;code&gt;2^19 = 85 r/s&lt;/code&gt;, &lt;code&gt;2^20 = 107 r/s&lt;/code&gt;, &lt;code&gt;2^21 = 123 r/s&lt;/code&gt; and &lt;code&gt;2^22 is 133 r/s&lt;/code&gt;. This doesnt quite match up with the observed values in the graph. Maybe some other cache is coming into effect here ?&lt;/p&gt;
&lt;h3&gt;sync,read,sync=0,direct=0&lt;/h3&gt;
&lt;p&gt;This is another interesting graph where we observe quite a different phenomenon. First, let's consider the &lt;code&gt;util&lt;/code&gt; column. We observe that until bs=7, the disk is actually underutilized. This means that until bs=7, the entire goddamn process is bottlenecked on CPU. Indeed, when I checked % cpu utilization through top, the CPU was at humming at 100%. Looking at the iops graph, it is constant until bs=7. We conclude that 900K iops is the theoritical maximum that the linux kernel can perform. So 1.1 microseconds per system call. Useful number to remember! 
Looking at the &lt;code&gt;r/s&lt;/code&gt; graph, it is fairly simple. Until bs=7, values keeps doubling. Why? when we double the fio block size, iops being constant, the kernel can read data twice as fast and will thus issue disk reads twice as fast. After bs=8, the number of &lt;code&gt;r/s&lt;/code&gt; have completely saturated. This is the time when the disk is 100% utilized and cpu/kernel/memory is no longer the bottleneck. The &lt;code&gt;rKB/s&lt;/code&gt; is uninteresting since it is simply following &lt;code&gt;r/s&lt;/code&gt; (because &lt;code&gt;avgrq-sz&lt;/code&gt; is constant). But note that we get around 140 MBps for sequential throughput. &lt;/p&gt;
&lt;p&gt;Now lets tackle &lt;code&gt;iops&lt;/code&gt;. We already explained the constant iops until bs=7. From bs=8, A couple of things are happening here. First note the &lt;code&gt;io&lt;/code&gt; column. For bs=8, we have read 11GB of data, so in the middle of the 60 second run, the entire file was page-cached in memory and the rest of time was served purely from ram. So the reduction in iops is because for some fraction of the 60 second time, we are actually bottlenecked on hard disk. For subsequent values of bs, the fraction of time of hard-disk bottleneck remains constant (and hence the fraction of time cpu bottlenecked also remains constant) but in the cpu bottleneck phase, since the block size has doubled, iops will have to halve. Note that in the initial stages values after bs=7. i.e., for bs=8, 9, 10 the decrease in iops is less than half. This is because the system_call/kernel overhead is still the majority of time. As block size gets bigger, The time copying from kernel space to user space overwhelms the systemCall/kernel time, and we observe proper halving of iops (see iops values bs=15). This also explains why &lt;code&gt;bw&lt;/code&gt; saturates after bs=15. It is caused because once kernel/systemCall time became negligible, the bandwidth is simply &lt;code&gt;iops*bs&lt;/code&gt;. This remains true for all subsequent values of bs.&lt;/p&gt;
&lt;p&gt;The story with &lt;code&gt;bw&lt;/code&gt; is similar. Up until bs=7, the bw has exactly doubled, because fio was 100% CPU bottlenecked. Starting from bs=8, there is a component that cannot be increased (when bottleneck is hard-disk) and there is a component that can be doubled (when bottleneck is cpu and 1microsecond system call processing time). So the average increase is 1.64 times previous value&lt;/p&gt;
&lt;h4&gt;Quantitative explanation&lt;/h4&gt;
&lt;p&gt;Assume the following numbers:
* Time to make one system call irrespective of block size = 1.1 microseconds
* RAM-to-RAM copy bandwidth 4.6 GBps (i.e., to copy from kernel space to user space)&lt;/p&gt;
&lt;p&gt;For bs=2^9, at the rate of 138 MBps disk read speed, the disk was busy for 3G/138MBps = 22.6 seconds. Number of fio io operations for the first 22.6 seconds= 3G/2^9 = 6291456.
For the next 60 - 22.6 = 37.4 seconds, requests were served purely from copying data from page cache to user space (RAM-to-RAM copy). Time for each io operation = 1.1 microseconds + 2^9 / 4.8GBps = 1.2 microseconds. So in 37.4 seconds, number of fio operations = 37.4 / 1.2 microseconds = 31.16 million fio operations. So net io operations = 31.16 million + 6291456 = 37458122. 
iops calculated over 60 seconds = 37458122/60 = 624302. This differs from actual value of 617759 by 1%.
The actual percentages of error using this method (starting from bs=512) is 
0.80, 3.64, 3.32, 9.78, 11.94, 13.33, 15.65, 15.38, 0.99, 10.13, 5.77, 3.85, 2.75, 3.17, 3.66, 12.44
Even with 15% error, its not too shabby i guess, in the face of other complications such as page faults and TLB misses&lt;/p&gt;
&lt;p&gt;Unexplained:
The &lt;code&gt;avgrq-sz&lt;/code&gt; seems to be stuck at 512 sectors. Why? we saw in the case of &lt;code&gt;libaio,randread,sync=0,direct=0&lt;/code&gt; that &lt;code&gt;avgrq-sz&lt;/code&gt; went upto 1024 sectors. &lt;/p&gt;
&lt;p&gt;explain the &lt;code&gt;bw&lt;/code&gt; from 2^16 onwards&lt;/p&gt;
&lt;p&gt;Quantitatively verify if the theories make sense. &lt;/p&gt;
&lt;h3&gt;sync,read,sync=1,direct=1&lt;/h3&gt;
&lt;p&gt;From bs=2^15 onwards, everything is straightforward. First, notice that iops follows r/s and bw follows rKB/s. This is expected for direct=1. So we can ignore those. 
The total time for an read operation = 1.1 microseconds (system call) + bs / (hdd bw = 130 MBps) + bs / (RAM bw = 4.8 BGps)&lt;/p&gt;
&lt;p&gt;The RAM bw is due to copying from kernel space to user space. &lt;/p&gt;
&lt;p&gt;The error percentages from computing r/s vs the actual r/s is as follows:
 5.72%, 5.19%, 6.72%, 5.22%, 5.25%, 5.68%, 6.52%, 8.25%, 11.86%, 19.85%&lt;/p&gt;
&lt;h5&gt;Unexplained&lt;/h5&gt;
&lt;p&gt;I am not able to explain what is going on for bs=2^{15, 16, 17}&lt;/p&gt;
&lt;h3&gt;sync,read,sync=0,direct={0,1}&lt;/h3&gt;
&lt;p&gt;This case is exactly the same as sync=1 because read operations are always sync=1. The sync=0 flag has no effect.&lt;/p&gt;
&lt;h3&gt;sync,randread,sync=0,direct=0&lt;/h3&gt;
&lt;p&gt;First, let us tackle the part of the graph until bs=2^19. Let's concentrate on r/s. In the beginning, the r/s is mainly influenced by the 5ms seek time for random read. This translates to ~170 reads per second. For later values of bs, starting from bs=2^15, the r/s starts dipping. What is happenning is that for bigger blocks, time taken to read a full block (at the rate of 130 MBps) starts dominating, which leads to a dip in r/s. &lt;/p&gt;
&lt;p&gt;Time taken for a read = 5ms (seek time) + bs / 110 MBps(hdd read throughput)&lt;/p&gt;
&lt;p&gt;The errors of computed vs actual r/s until bs=19 is as follows:
0.48%, 2.19%, 2.77%, 3.96%, 1.61%, 2.19%, 1.03%, 2.17%, 2.15%, 2.11%, 2.03%, 0.72%, 2.12%, 2.65%, 0.79%, 4.34%, 3.28%, -1.75%, 3.80%, 0.98%
As you can see, its remarkably accurate&lt;/p&gt;
&lt;p&gt;For rKB/s, the computed value is r/s * avgrq-sz
When we measure the difference between computed rKB/s and actual rKB/s, we get:
0.48%, 2.19%, 2.77%, 3.96%, 1.61%, 2.19%, 1.03%, 2.17%, 2.15%, 2.11%, 2.03%, 0.72%, 2.12%, 2.65%, 0.79%, 4.34%, 3.28%, -1.75%, 3.80%, 0.98%
The error rates are exactly the same as r/s which stresses that &lt;code&gt;rKB/s&lt;/code&gt; is a computed value rather than an independant value.&lt;/p&gt;
&lt;p&gt;For the bw graph. It is simply following &lt;code&gt;rKB/s&lt;/code&gt; until bs=19&lt;/p&gt;
&lt;p&gt;The iops graph is explained simply as &lt;code&gt;bw/bs&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;It is also easy to explain the graph from bs=20 onwards. Each fio block translates into bs/avrq-sq sequential disk read operations. For example, A fio block of size 2 MB results in 4 sequential reads (each of 1024 sectors = 0.5 MB). That explains the sudden increase in r/s after bs=19. 
If we now use hdd throughput = 120 MBps (retrofitted, but i've seen the throughput varying between 110-120MBps) with the formula &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;computed_read_s = (bs / (1024*512)) / (5.6*10**-3 + bs/(120*2**20) )
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The errors against actual values are as follows:
0.38%, 0.92%, -1.21%, -4.98%, -1.99%&lt;/p&gt;
&lt;p&gt;As always, the &lt;code&gt;rKB/s&lt;/code&gt; is r/s*avgrq-sz&lt;/p&gt;
&lt;p&gt;The iops and the bw graph is more interesting. Another thing that happened at bs=19 was that the page-cache was completely filled. (see the io column) This results in requests being served from RAM which explains the tremendous shootup in fio iops and fio bw&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;number of ios for reading the 3G file into memory = 3G/bs ------&amp;gt; (3)
time to read it from hard disk = 3G/rKBps
time for which requests were served from page-cache = 60-3G/rKBps   ----&amp;gt; (1)
Time of a single page-cache io operation = 1.1 microseconds + bs / (4.8 GBps = ram  bandwidth) ----&amp;gt; (2)
expected iops = ((3)+(1)/(2)) / 60
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;With the above formula, the errors of expected vs actual are 
10.11%, 1.39%, 2.22%, 3.41%, 9.97%&lt;/p&gt;
&lt;p&gt;The 10% variation is not unreasonable with the complicated L* cache hierarchies of modern processors&lt;/p&gt;
&lt;p&gt;The bw graph is simply iops * bs&lt;/p&gt;</content><category term="misc"></category><category term="misc"></category></entry><entry><title>Setting up a ceph cluster</title><link href="/setting-up-a-ceph-cluster.html" rel="alternate"></link><published>2016-02-07T10:20:00+00:00</published><updated>2016-02-07T10:20:00+00:00</updated><author><name>Sharath Gururaj</name></author><id>tag:None,2016-02-07:/setting-up-a-ceph-cluster.html</id><summary type="html">&lt;p&gt;The instructions &lt;a href="http://docs.ceph.com/docs/hammer/install/manual-deployment/"&gt;here&lt;/a&gt; mostly work. Except that the &lt;code&gt;ceph.conf&lt;/code&gt; file  given there doesnt work. Because, when I issue &lt;code&gt;sudo /etc/init.d/ceph start mon.node1&lt;/code&gt; in the end, It expects a section in &lt;code&gt;ceph.   conf&lt;/code&gt; called &lt;code&gt;[mon.node1]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Furthermore, to launch a radosgw instance, you &lt;em&gt;need&lt;/em&gt; to have …&lt;/p&gt;</summary><content type="html">&lt;p&gt;The instructions &lt;a href="http://docs.ceph.com/docs/hammer/install/manual-deployment/"&gt;here&lt;/a&gt; mostly work. Except that the &lt;code&gt;ceph.conf&lt;/code&gt; file  given there doesnt work. Because, when I issue &lt;code&gt;sudo /etc/init.d/ceph start mon.node1&lt;/code&gt; in the end, It expects a section in &lt;code&gt;ceph.   conf&lt;/code&gt; called &lt;code&gt;[mon.node1]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Furthermore, to launch a radosgw instance, you &lt;em&gt;need&lt;/em&gt; to have a section in your host file called &lt;code&gt;client.rgw.&amp;lt;some_name&amp;gt;&lt;/code&gt; and your  keyring should have a corresponding key section called  &lt;code&gt;client.rgw.&amp;lt;some_name&amp;gt;&lt;/code&gt; and you should have imported that key into ceph    via &lt;code&gt;sudo ceph auth import -i /etc/ceph/&amp;lt;keyring_file&amp;gt;&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;All the three names must match: the one in ceph.conf, in the keyring and in &lt;code&gt;ceph auth list&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Oh, and yeah, do &lt;strong&gt;NOT&lt;/strong&gt; put a line like this in your &lt;code&gt;ceph.conf&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;rgw&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;data&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;/var/lib/ceph/radosgw/ceph-rgw.prod-d42sa-rgw-a-287004
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;If you do, you'l get weird messages like &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Couldn't init storage provider (RADOS)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;and you'll go crazy trying to debug it.&lt;/p&gt;
&lt;p&gt;So the working &lt;code&gt;ceph.conf&lt;/code&gt; with comments is: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="o"&gt;[&lt;/span&gt;global&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;fsid&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;a7f64266-0894-4f1e-a635-d0aeaca0e993&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;#anything random, generated from uuidgen&lt;/span&gt;
auth&lt;span class="w"&gt; &lt;/span&gt;cluster&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;required&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;cephx
auth&lt;span class="w"&gt; &lt;/span&gt;service&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;required&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;cephx
auth&lt;span class="w"&gt; &lt;/span&gt;client&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;required&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;cephx
osd&lt;span class="w"&gt; &lt;/span&gt;journal&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;size&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;1024&lt;/span&gt;
filestore&lt;span class="w"&gt; &lt;/span&gt;xattr&lt;span class="w"&gt; &lt;/span&gt;use&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;omap&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;true&lt;/span&gt;
osd&lt;span class="w"&gt; &lt;/span&gt;pool&lt;span class="w"&gt; &lt;/span&gt;default&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;size&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
osd&lt;span class="w"&gt; &lt;/span&gt;pool&lt;span class="w"&gt; &lt;/span&gt;default&lt;span class="w"&gt; &lt;/span&gt;min&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;size&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
osd&lt;span class="w"&gt; &lt;/span&gt;pool&lt;span class="w"&gt; &lt;/span&gt;default&lt;span class="w"&gt; &lt;/span&gt;pg&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;num&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;333&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
osd&lt;span class="w"&gt; &lt;/span&gt;pool&lt;span class="w"&gt; &lt;/span&gt;default&lt;span class="w"&gt; &lt;/span&gt;pgp&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;num&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;333&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
osd&lt;span class="w"&gt; &lt;/span&gt;crush&lt;span class="w"&gt; &lt;/span&gt;chooseleaf&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
&lt;span class="c1"&gt;# useful for debugging&lt;/span&gt;
&lt;span class="o"&gt;[&lt;/span&gt;mon&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;debug&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;mon&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;20&lt;/span&gt;
&lt;span class="o"&gt;[&lt;/span&gt;osd&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;debug&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;osd&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;20&lt;/span&gt;
&lt;span class="o"&gt;[&lt;/span&gt;rgw&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;debug&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;rgw&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;20&lt;/span&gt;
&lt;span class="o"&gt;[&lt;/span&gt;mon.node1&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;# as many sections as monitors&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nv"&gt;host&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;dev-d42sharath1-mon-a-0001-389313&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;#This NEEDS to be the actual hostname donno for what reasons&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;mon&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;addr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;10&lt;/span&gt;.33.29.199&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;# needs to be the actual address.&lt;/span&gt;
&lt;span class="o"&gt;[&lt;/span&gt;client.rgw.foo&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nv"&gt;host&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;dev-d42sharath1-rgw-a-0001-389309
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nv"&gt;keyring&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;/etc/ceph/ceph.client.rgw.keyring
&lt;span class="w"&gt;    &lt;/span&gt;log&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;file&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;/var/log/radosgw/client.radosgw.gateway.log
&lt;span class="w"&gt;    &lt;/span&gt;rgw&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;frontends&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;civetweb&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;port&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;80&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;rgw&lt;span class="w"&gt; &lt;/span&gt;print&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;continue&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;false&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content><category term="misc"></category><category term="ceph"></category></entry><entry><title>I finally setup a blog</title><link href="/i-finally-setup-a-blog.html" rel="alternate"></link><published>2016-02-02T22:20:00+00:00</published><updated>2016-02-02T22:20:00+00:00</updated><author><name>Sharath Gururaj</name></author><id>tag:None,2016-02-02:/i-finally-setup-a-blog.html</id><summary type="html">&lt;p&gt;&lt;strong&gt;I finally setup my own blog!&lt;/strong&gt; and i'm happy I did it the right way. No lame wordpress. I bought a virtual private server on &lt;a href="www.digitalocean.com"&gt;digital ocean&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;Virtual private server (or a droplet in digitalocean lingo) is a fancy name for your own computer in the cloud, which you can …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;strong&gt;I finally setup my own blog!&lt;/strong&gt; and i'm happy I did it the right way. No lame wordpress. I bought a virtual private server on &lt;a href="www.digitalocean.com"&gt;digital ocean&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;Virtual private server (or a droplet in digitalocean lingo) is a fancy name for your own computer in the cloud, which you can ssh into and have   root access. It cost me ~Re 300 per month for their most basic droplet. I set it up with a static ipv4.&lt;/p&gt;
&lt;p&gt;Since digitalocean has no DNS service, I bought a domain on &lt;a href="www.namecheap.com"&gt;namecheap&lt;/a&gt; for Re 500 per year and pointed it to the droplet. I   am hosting this as a static site powered by pelican. Using the built-in python server for now.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;UPDATE (11th may 2016):&lt;/strong&gt; Paying monthly to digital ocean was getting to be a pain. So I have moved to github pages, which is just as simple.  &lt;/p&gt;</content><category term="misc"></category><category term="misc"></category></entry></feed>